<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.29">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-06-25">

<title>5&nbsp; Monte Carlo Methods ‚Äì Notes on Sutton &amp; Barto</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../chapters/06-temporal-difference-learning.html" rel="next">
<link href="../chapters/04-dynamic-programming.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-6fc64a0c1cda8d1c841de64652c337fd.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-6fc64a0c1cda8d1c841de64652c337fd.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-fb02f3c877dd64dca3cf6a6e57462b95.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-72e3104a5210017f14ac4024f5014c88.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating quarto-dark"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = true;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../chapters/05-monte-carlo-methods.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Monte Carlo Methods</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Notes on Sutton &amp; Barto</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/julxi/notes_and_solutions_reinforcement_learning" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/02-multi-armed-bandits.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Multi-armed Bandits</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/03-finite-markov-decision-processes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Finite Markov Decision Processes</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/04-dynamic-programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Dynamic Programming</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/05-monte-carlo-methods.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Monte Carlo Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../chapters/06-temporal-difference-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Temporal-Difference Learning (Still in Progress üî®)</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#monte-carlo-prediction" id="toc-monte-carlo-prediction" class="nav-link active" data-scroll-target="#monte-carlo-prediction"><span class="header-section-number">5.1</span> Monte Carlo Prediction</a></li>
  <li><a href="#monte-carlo-estimation-of-action-values" id="toc-monte-carlo-estimation-of-action-values" class="nav-link" data-scroll-target="#monte-carlo-estimation-of-action-values"><span class="header-section-number">5.2</span> Monte Carlo Estimation of Action Values</a></li>
  <li><a href="#monte-carlo-control" id="toc-monte-carlo-control" class="nav-link" data-scroll-target="#monte-carlo-control"><span class="header-section-number">5.3</span> Monte Carlo Control</a></li>
  <li><a href="#monte-carlo-control-without-exploring-starts" id="toc-monte-carlo-control-without-exploring-starts" class="nav-link" data-scroll-target="#monte-carlo-control-without-exploring-starts"><span class="header-section-number">5.4</span> Monte Carlo Control without Exploring Starts</a></li>
  <li><a href="#sec-off-policy-prediction-via-importance-sampling" id="toc-sec-off-policy-prediction-via-importance-sampling" class="nav-link" data-scroll-target="#sec-off-policy-prediction-via-importance-sampling"><span class="header-section-number">5.5</span> Off-policy Prediction via Importance Sampling</a>
  <ul class="collapse">
  <li><a href="#importance-sampling-for-the-rubber-sheet-problem" id="toc-importance-sampling-for-the-rubber-sheet-problem" class="nav-link" data-scroll-target="#importance-sampling-for-the-rubber-sheet-problem"><span class="header-section-number">5.5.1</span> üóê Importance Sampling for the Rubber Sheet Problem</a></li>
  <li><a href="#importance-sampling-in-ml" id="toc-importance-sampling-in-ml" class="nav-link" data-scroll-target="#importance-sampling-in-ml"><span class="header-section-number">5.5.2</span> üóê Importance Sampling in ML</a></li>
  <li><a href="#bias-mse-and-all-that" id="toc-bias-mse-and-all-that" class="nav-link" data-scroll-target="#bias-mse-and-all-that"><span class="header-section-number">5.5.3</span> üóê Bias, MSE, and All That</a></li>
  </ul></li>
  <li><a href="#incremental-implementation" id="toc-incremental-implementation" class="nav-link" data-scroll-target="#incremental-implementation"><span class="header-section-number">5.6</span> Incremental Implementation</a></li>
  <li><a href="#off-policy-monte-carlo-control" id="toc-off-policy-monte-carlo-control" class="nav-link" data-scroll-target="#off-policy-monte-carlo-control"><span class="header-section-number">5.7</span> Off-policy Monte Carlo Control</a></li>
  <li><a href="#appendix" id="toc-appendix" class="nav-link" data-scroll-target="#appendix"><span class="header-section-number">5.8</span> üóê Appendix</a>
  <ul class="collapse">
  <li><a href="#sec-mc-is-slow" id="toc-sec-mc-is-slow" class="nav-link" data-scroll-target="#sec-mc-is-slow"><span class="header-section-number">5.8.1</span> Monte Carlo is Slow</a></li>
  <li><a href="#sec-confidence-intervals" id="toc-sec-confidence-intervals" class="nav-link" data-scroll-target="#sec-confidence-intervals"><span class="header-section-number">5.8.2</span> Confidence intervals</a></li>
  <li><a href="#sec-strip-problem" id="toc-sec-strip-problem" class="nav-link" data-scroll-target="#sec-strip-problem"><span class="header-section-number">5.8.3</span> The strip problem</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Monte Carlo Methods</span></h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 25, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>In this chapter ‚ÄòMonte Carlo‚Äô means sampling complete episodes. Monte Carlo methods have the following properties:</p>
<ul>
<li>use experience</li>
<li>only applicable for episodic tasks</li>
<li>updates happen only after an episode</li>
<li>the MDPs should terminate no matter which actions are taken. This is actually a theoretical assumption, as practically we can‚Äôt deal with finite but very long episodes either</li>
</ul>
<section id="monte-carlo-prediction" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="monte-carlo-prediction"><span class="header-section-number">5.1</span> Monte Carlo Prediction</h2>
<p>For prediction, we have two variants of Monte Carlo methods:</p>
<ul>
<li>every-visit MC: maybe more intuitive but theoretical harder to analyse.</li>
<li>first-visit MC: seems a bit wasteful at first but returns are independent. It can be beneficial to count a state only once, otherwise huge visit counts to a state in a single episode can have big impacts on the value estimate.</li>
</ul>
<p>Both variants converge to <span class="math inline">\(v_\pi(s)\)</span> if every <span class="math inline">\(s\)</span> is visited infinitely often. The algorithm is stochastic, that‚Äôs why we loop forever in the pseudocode to get asymptotic guarantee. In real code, we have to have some stop condition. For example, a simple ‚Äúhigh number of iterations and then fingers crossed‚Äù.</p>
<div id="lst-mc-prediction-first-visit" class="listing-block listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-mc-prediction-first-visit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;5.1: First-visit MC prediction, for estimating <span class="math inline">\(V \approx v_\pi\)</span>
</figcaption>
<div aria-describedby="lst-mc-prediction-first-visit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="line-block"><strong>Input</strong>: <span class="math inline">\(\pi\)</span>, the policy to be evaluated<br>
<strong>Initialisation</strong>: <span class="math inline">\(V(s)\)</span>, for all <span class="math inline">\(s \in \mathcal{S}\)</span> arbitrarily<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\mathrm{Returns}(S_t) \gets\)</span> empty list, for all <span class="math inline">\(s \in \mathcal{S}\)</span><br>
<br>
Loop forever:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Generate an episode following <span class="math inline">\(\pi\)</span>: <span class="math inline">\(S_0,A_0, R_1, S_1, A_1, \dots, R_T, S_T\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(G \gets 0\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;Loop for each step of episode, <span class="math inline">\(t = T-1, T-2, \dots, 0\)</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(G \gets \gamma G + R_{t+1}\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If <span class="math inline">\(S_t\)</span> is not in <span class="math inline">\(\{S_0,S_1, \dots, S_{t-1}\}\)</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Append <span class="math inline">\(G\)</span> to <span class="math inline">\(\mathrm{Returns}(S_t)\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(V(S_t) \gets \mathrm{average}(\mathrm{Returns}(S_t))\)</span></div>
</div>
</figure>
</div>
<div id="exm-5.1-blackjack" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.1</strong></span> This is Example 5.1: <strong>Blackjack</strong> from <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span>.</p>
<p>Get your infinite deck ready, we‚Äôre heading to the casinos.</p>
<p>Here is a not-so-short summary of the Blackjack variant used in the source. I tried to keep it concise but also precise, the devil lives in the details here.</p>
<ul>
<li>player competes against the dealer</li>
<li>both parties collect cards and if one‚Äôs hand value exceeds 21 they automatically lose the game (go bust).</li>
<li>the deck is ‚Äúinfinite‚Äù, i.e., the chances for any card are always like in a freshly shuffled deck.</li>
<li>the numbered cards go from 1 to 10, the value of face cards is 10 except ace which is valued as 1 or 11 if that doesn‚Äôt result in a bust.</li>
<li>game begins with two cards dealt to the player and dealer each. The player can see the first card of the dealer but not the second.</li>
<li>right after the hands have been dealt, if the player or the dealer have 21 they have a natural and immediately win, or it‚Äôs a draw if both have 21.</li>
<li>if there are no naturals the player can hit‚Äîrequest a new card‚Äîuntil he sticks‚Äîstop and let the dealer collect cards.</li>
<li>the dealer plays to this fixed strategy, they will hit when they have less than 17, and stick otherwise.</li>
<li>if neither the player nor the dealer go bust during their turns, the party with the highest total wins, or it‚Äôs a draw.</li>
</ul>
<p>The rule about naturals that I use here seems to be different from what‚Äôs stated in <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span> which reads as ‚Äúthe dealer‚Äôs second card is only checked if the player has a natural‚Äù. However, I don‚Äôt know which rule they used in their implementation though. This is actually an important point for the distribution of the cards. Following ‚Äòmy‚Äô rules, if the game has properly started‚Äîno party has a natural‚Äîand the dealer‚Äôs showing card is an ace, it is guaranteed that the dealer‚Äôs second card‚Äîthe one face down‚Äîwill not be a 10.</p>
<p>This is how we set up Blackjack as an MDP:</p>
<ul>
<li>Each game is an episode with reward: +1 (win), -1 (loss), 0 (draw).</li>
<li>The state is represented as <span class="math display">\[
(\text{player's total}, \text{player has usable ace}, \text{dealer's showing card}),
\]</span> where a usable ace means that the hand has one ace that counts as 11 (soft hand).</li>
<li>W.l.o.g. we can assume that the player‚Äôs total is at least 12 as for any value below, there is no chance to go bust and we disregard any incredibly stupid policies that would stick in these kind of situations.</li>
<li>All that stuff about naturals are not part of the dynamics of the MDP, the game basically ends before it has properly started. They influence the starting states though, as described above.</li>
</ul>
<p>The strategy we want to evaluate using MC prediction is quite greedy. The agent only sticks on a 20 or 21 otherwise hits. I implemented the Blackjack environment separately and just use it here.</p>
<div id="a35561b5" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === a quite greedy Blackjack policy ===</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scripts.environment.black_jack <span class="im">import</span> BlackJack, Action, State</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> BlackJack()</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>œÄ_at_least_20 <span class="op">=</span> {}</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> state <span class="kw">in</span> env.state_space:</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> state.player_total <span class="op">&lt;</span> <span class="dv">20</span>:</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        œÄ_at_least_20[state] <span class="op">=</span> Action.HIT</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        œÄ_at_least_20[state] <span class="op">=</span> Action.STICK</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now let‚Äôs set up the code for <a href="06-temporal-difference-learning.html#lst-mc-prediction-first-visit" class="quarto-xref">Listing&nbsp;<span>6.1</span></a>. We need to make a few changes:</p>
<ul>
<li>Include a stop condition‚Äîa simple step counter.</li>
<li>Calculate the averages for the state-value approximation just once at the end.</li>
<li>To implement first visit, start with a count of all the states. Then, for each <span class="math inline">\(S_t\)</span>, decrease the counter for that state until it‚Äôs one, then we know this is the first visit.</li>
<li>I added a <span class="math inline">\(R_0\)</span> which corresponds to naturals (episode starts in a terminal state). However, we ignore these as we only calculate rewards for non-terminal states. This means a fraction of the generated episodes won‚Äôt give any experience.</li>
</ul>
<div id="9dea65fc" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === MC prediction for Blackjack ===</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter, defaultdict</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statistics</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scripts.environment.black_jack <span class="im">import</span> BlackJack, Action, State, Reward</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_episode(env, œÄ) <span class="op">-&gt;</span> <span class="bu">tuple</span>[<span class="bu">list</span>[State], <span class="bu">list</span>[Reward], <span class="bu">list</span>[Action]]:</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    states <span class="op">=</span> []  <span class="co"># S_0, ..., S_T</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    rewards <span class="op">=</span> []  <span class="co"># R_0, ..., R_T</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    actions <span class="op">=</span> []  <span class="co"># A_0, ..., A_{T-1}</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    state, reward, terminated <span class="op">=</span> env.reset()</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    states.append(state)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    rewards.append(reward)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> terminated:</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        action <span class="op">=</span> œÄ[state]</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        actions.append(action)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        state, reward, terminated <span class="op">=</span> env.step(action)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>        states.append(state)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        rewards.append(reward)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> states, rewards, actions</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mc_prediction(env, œÄ, n_episodes):</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    returns <span class="op">=</span> defaultdict(<span class="bu">list</span>)</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_episodes):</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>        states, rewards, actions <span class="op">=</span> generate_episode(env, œÄ)</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>        G <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>        visit_counter <span class="op">=</span> Counter(states)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(<span class="bu">len</span>(actions))):</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>            G <span class="op">+=</span> rewards[i <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>            state <span class="op">=</span> states[i]</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> visit_counter[state] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>                returns[state].append(G)</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>                visit_counter[state] <span class="op">+=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>    V <span class="op">=</span> {}</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> state <span class="kw">in</span> env.state_space:</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(returns[state]) <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>            V[state] <span class="op">=</span> statistics.mean(returns[state])</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> V</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>iterations <span class="op">=</span> <span class="dv">1</span>  <span class="co"># todo: this should be 5_000_000</span></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>value <span class="op">=</span> mc_prediction(env, œÄ_at_least_20, iterations)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here we can see the state-value function as heatmap.</p>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">## plotting</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># def plt_grid_for_blackjack</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare axes</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>player_sums <span class="op">=</span> np.arange(<span class="dv">12</span>, <span class="dv">22</span>)  <span class="co"># 12‚Äì21</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>dealer_cards <span class="op">=</span> np.arange(<span class="dv">2</span>, <span class="dv">12</span>)  <span class="co"># 2‚Äì11 (11==Ace)</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper to build a matrix for usable_ace = True/False</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_grid(value_dict, usable_ace_flag):</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    grid <span class="op">=</span> np.zeros((<span class="bu">len</span>(player_sums), <span class="bu">len</span>(dealer_cards)))</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, ps <span class="kw">in</span> <span class="bu">enumerate</span>(player_sums):</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j, dc <span class="kw">in</span> <span class="bu">enumerate</span>(dealer_cards):</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Create a State object with the current parameters</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>            state <span class="op">=</span> State(</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>                player_total<span class="op">=</span>ps,</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>                is_soft<span class="op">=</span>usable_ace_flag,</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>                dealer_revealed<span class="op">=</span>dc,</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Look up the value using the State object</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>            grid[i, j] <span class="op">=</span> value_dict.get(state, np.nan)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> grid</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the two grids</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>grid_no_ace <span class="op">=</span> build_grid(value, <span class="va">False</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>grid_with_ace <span class="op">=</span> build_grid(value, <span class="va">True</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot with usable ace</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>plt.imshow(</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    grid_with_ace, origin<span class="op">=</span><span class="st">"lower"</span>, aspect<span class="op">=</span><span class="st">"auto"</span>, vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">"coolwarm"</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(grid_no_ace.shape[<span class="dv">0</span>]):</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(grid_no_ace.shape[<span class="dv">1</span>]):</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        plt.text(</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>            j,</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>            i,</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"</span><span class="sc">{</span>grid_with_ace[i, j]<span class="sc">:.2f}</span><span class="ss">"</span>,</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>            ha<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>            va<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>            color<span class="op">=</span><span class="st">"black"</span>,</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>            fontsize<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>plt.xticks(ticks<span class="op">=</span>np.arange(<span class="bu">len</span>(dealer_cards)), labels<span class="op">=</span>dealer_cards)</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>plt.yticks(ticks<span class="op">=</span>np.arange(<span class="bu">len</span>(player_sums)), labels<span class="op">=</span>player_sums)</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Dealer's Showing Card"</span>)</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Player's Total"</span>)</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"MC Value Function (With Usable Ace), </span><span class="sc">{</span>iterations<span class="sc">:,}</span><span class="ss"> Iterations"</span>)</span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 1: no usable ace</span></span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>plt.imshow(grid_no_ace, origin<span class="op">=</span><span class="st">"lower"</span>, aspect<span class="op">=</span><span class="st">"auto"</span>, vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>, cmap<span class="op">=</span><span class="st">"coolwarm"</span>)</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(grid_no_ace.shape[<span class="dv">0</span>]):</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(grid_no_ace.shape[<span class="dv">1</span>]):</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a>        plt.text(</span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a>            j,</span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a>            i,</span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"</span><span class="sc">{</span>grid_no_ace[i, j]<span class="sc">:.2f}</span><span class="ss">"</span>,</span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>            ha<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a>            va<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>            color<span class="op">=</span><span class="st">"black"</span>,</span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>            fontsize<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a>plt.xticks(ticks<span class="op">=</span>np.arange(<span class="bu">len</span>(dealer_cards)), labels<span class="op">=</span>dealer_cards)</span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a>plt.yticks(ticks<span class="op">=</span>np.arange(<span class="bu">len</span>(player_sums)), labels<span class="op">=</span>player_sums)</span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Dealer's Showing Card"</span>)</span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Player's Total"</span>)</span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"MC Value Function (No Usable Ace), </span><span class="sc">{</span>iterations<span class="sc">:,}</span><span class="ss"> Iterations"</span>)</span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-blackjack-state-value-function-greedy-policy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-blackjack-state-value-function-greedy-policy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="5a9a32d6" class="cell" data-execution_count="4">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-4-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;5.1: This is like Figure 5.1 from @sutton2018. It shows the approximate state-value function for the Blackjack policy that sticks only for 20 or 21, computed by MC policy evaluation."><img src="05-monte-carlo-methods_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-4-output-2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;5.1: This is like Figure 5.1 from @sutton2018. It shows the approximate state-value function for the Blackjack policy that sticks only for 20 or 21, computed by MC policy evaluation."><img src="05-monte-carlo-methods_files/figure-html/cell-4-output-2.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-blackjack-state-value-function-greedy-policy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.1: This is like Figure 5.1 from <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span>. It shows the approximate state-value function for the Blackjack policy that sticks only for 20 or 21, computed by MC policy evaluation.
</figcaption>
</figure>
</div>
</div>
<div id="exr-5.1" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.1</strong></span> Consider the diagrams in <a href="#fig-blackjack-state-value-function-greedy-policy" class="quarto-xref">Figure&nbsp;<span>5.1</span></a>. Why does the estimated value function jump up for the last two rows in the top<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>? Why does it drop off for dealer‚Äôs showing card is 11?<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> Why are the lowermost values higher in the upper diagrams than in the lower?</p>
</div>
<div id="sol-5.1" class="proof solution">
<p><span class="proof-title"><em>Solution 5.1</em>. </span>Let‚Äôs answer each question separately:</p>
<ul>
<li>the jump at the top: this come from the fact that for 20 or 21 the player sticks and for those values the odds of beating the dealer are quite high. The lower values are all negative meaning, that the player is likely to loose because ‚Äì I think ‚Äì with this strategy the agent is quite likely to go bust. The negative values indicate the expected loss for the player, not just that the player is likely to lose.</li>
<li>this drop off that is not visible in my diagram: in the original diagram the dropoff is between ‚ÄúDealer‚Äôs showing card‚Äù is 2 and Ace. But there is no drop off visible in my diagram. I have the theory that their code does not check for dealer naturals which would make a dealer‚Äôs showing ace more dangerous.</li>
<li>All cell values in the upper diagram are higher for player‚Äôs total less than 20 as the agent has a better chance to reach 20 or 21 without going bust with an ace up its hand. The rows for player‚Äôs total of 20 and 21 should return the same values as the agent chooses to stick in both cases, and the expected outcome is the same.</li>
</ul>
</div>
<div id="exr-5.2" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.2</strong></span> Suppose every-visit MC was used instead of first-visit MC on the blackjack task. Would you expect the results to be very different? Why or why not?</p>
</div>
<div id="sol-5.2" class="proof solution">
<p><span class="proof-title"><em>Solution 5.2</em>. </span>The results would be exactly the same as there is no way to visit a state a second time in blackjack (player‚Äôs total goes up or usable ace flag becomes false, and usable ace flag can only become true once).</p>
</div>
<div id="exm-soap-bubble" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.2</strong></span> This is example 5.2: Soap Bubble from <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span>.</p>
<p>Take a closed wire frame and dip it into soapy water. We do not want to blow any bubbles; we only want to predict the shape the soap film spans over the frame. If the wire frame is not too wild, we can represent it by prescribing a height function <span class="math inline">\(h\)</span> on the boundary of some planar region. The plot below shows how this can look.</p>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> cm</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Parameters and calculations ---</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>radius <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>offset <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">35</span>  <span class="co"># resolution (should be 200)</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">35</span>  <span class="co"># patching (should be 200)</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># mesh</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span>radius, radius, n)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.linspace(<span class="op">-</span>radius, radius, n)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>x, y <span class="op">=</span> np.meshgrid(x, y)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># disk</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> np.sqrt(x<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> y<span class="op">**</span><span class="dv">2</span>) <span class="op">&lt;=</span> radius</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co"># circle</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span> np.pi, n)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>x_circle <span class="op">=</span> radius <span class="op">*</span> np.cos(theta)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>y_circle <span class="op">=</span> radius <span class="op">*</span> np.sin(theta)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co"># outline and film height</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>z_circle <span class="op">=</span> x_circle<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> y_circle<span class="op">**</span><span class="dv">2</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> np.where(mask, x<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> y<span class="op">**</span><span class="dv">2</span>, np.nan)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Create figure ---</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">"3d"</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co"># outline shadow</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>ax.contourf(</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    x,</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    y,</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    np.where(mask, <span class="dv">0</span>, np.nan),</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    zdir<span class="op">=</span><span class="st">"z"</span>,</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.3</span>,</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="co"># wire</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>ax.plot(</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    x_circle,</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    y_circle,</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>    z_circle <span class="op">+</span> offset,</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">"black"</span>,</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    linewidth<span class="op">=</span><span class="fl">2.5</span>,</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a><span class="co"># soap film</span></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>surf <span class="op">=</span> ax.plot_surface(</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    x,</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    y,</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>    z <span class="op">+</span> offset,</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">"prism"</span>,</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>    linewidth<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.75</span>,</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>    antialiased<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>    shade<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>    rcount<span class="op">=</span>p,</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>    ccount<span class="op">=</span>p,</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a><span class="co"># no tick marks</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels([])</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>ax.set_yticklabels([])</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>ax.set_zticklabels([])</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">""</span>)</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">""</span>)</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>ax.set_zlabel(<span class="st">""</span>)</span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>ax.view_init(elev<span class="op">=</span><span class="dv">20</span>, azim<span class="op">=</span><span class="dv">110</span>)</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"A soapy Pringle"</span>, pad<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-soap-film" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-soap-film-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="e0796407" class="cell" data-execution_count="5">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;5.2: This shows a Pringle-shaped soap film. The black outline is the wire frame; the rainbow surface is the film itself. The figure is modelled by a height function on the grey disk in the xy-plane. The underlying physics in @sutton2018, which I used for this plot, is not quite right, so this is only an approximation."><img src="05-monte-carlo-methods_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-soap-film-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.2: This shows a Pringle-shaped soap film. The black outline is the wire frame; the rainbow surface is the film itself. The figure is modelled by a height function on the grey disk in the <span class="math inline">\(xy\)</span>-plane. The underlying physics in <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span>, which I used for this plot, is not quite right, so this is only an approximation.
</figcaption>
</figure>
</div>
<hr>
<p>The question is: given the height on the boundary, what is the height <span class="math inline">\(h\)</span> at interior points? <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span> set up the problem like this:</p>
<blockquote class="blockquote">
<p>Suppose a wire frame forming a closed loop is dipped into soapy water to form a soap surface or bubble conforming to the wire frame at its edges. If the geometry of the wire frame is irregular but known, how can you compute the shape of the surface? The shape has the property that the total force on each point exerted by neighboring points is zero (or else the shape would change). This means that the height at any point is the average of the heights at points in a small circle around that point.</p>
</blockquote>
<p>That last sentence as stated is not correct for soap films. It is true for elastic sheets like rubber, for which the restoring force is proportional to local displacement (to first order). In that case, the height function <span class="math inline">\(h\)</span> satisfies the mean-value property: its value at a point equals asymptotically the average of values on small circles around that point. This is equivalent to <span class="math inline">\(h\)</span> being a <a href="https://en.wikipedia.org/wiki/Harmonic_function">harmonic function</a>: <span id="eq-harmonic"><span class="math display">\[
\Delta h = \frac{\partial^2 h}{\partial x^2} + \frac{\partial^2 h}{\partial y^2} = 0.
\tag{5.1}\]</span></span></p>
<p>Soap films differ. Their molecules do not ‚Äústretch out.‚Äù What contracts is surface tension, which makes them shrink into minimal surfaces. For more information about the physics behind this, I recommend <span class="citation" data-cites="oprea2000">Oprea (<a href="#ref-oprea2000" role="doc-biblioref">2000</a>)</span>. Here, I will state the relevant result: A soap surface given as the graph <span class="math inline">\(z = h(x, y)\)</span> satisfies the nonlinear <a href="https://en.wikipedia.org/wiki/Minimal_surface">minimal-surface equation</a> <span class="citation" data-cites="oprea2000">(<a href="#ref-oprea2000" role="doc-biblioref">Oprea 2000</a>, Proposition 3.2.3)</span> <span id="eq-minimal-surface"><span class="math display">\[
h_{xx}(1 + h_y^2) - 2h_x h_y h_{xy} + h_{yy}(1 + h_x^2) = 0,
\tag{5.2}\]</span></span> where <span class="math inline">\(h_x, h_{xy}, \dots\)</span> are the partial derivatives <span class="math inline">\(\frac{\partial h}{\partial x}, \frac{\partial^2 h}{\partial x \partial y}\)</span>, etc.</p>
<p>This is generally not equivalent to being harmonic, so the mean-value property does not hold for a soap film in general. However, there is an approximation. When higher powers of the partial derivatives are small, a soap film is well approximated by a harmonic function <span class="citation" data-cites="oprea2000">(<a href="#ref-oprea2000" role="doc-biblioref">Oprea 2000</a>, Exercise 4.4.9)</span>. This is why the picture in <a href="#fig-soap-film" class="quarto-xref">Figure&nbsp;<span>5.2</span></a> ‚Äî which simply plots the harmonic function <span class="math inline">\(x^2 - y^2\)</span> inside a disk ‚Äî is only an approximation and not an exact minimal surface. Because of this distinction, I replace the ‚Äúsoap film problem‚Äù with the ‚Äúrubber sheet problem‚Äù in these notes.</p>
<p>We discretize the equation for harmonic functions so we can solve it numerically. On a rectangular grid, we enforce the discrete mean-value property at interior nodes: for each interior node <span class="math inline">\((x, y)\)</span>, <span class="math display">\[
h(x, y) = \frac{1}{4} \sum_{(x', y') \in B(x, y)} h(x', y'),
\]</span> where <span class="math inline">\(B(x, y) = \{(x', y'): |x - x'| + |y - y'| = 1\}\)</span>.</p>
<p>Equivalently, <span class="math inline">\(h\)</span> at an interior site equals the expected boundary value reached by a simple (nearest-neighbor) random walk started at that site. Thus, we can use Monte Carlo methods for solving the rubber sheet problem: run many independent random walks from <span class="math inline">\((x, y)\)</span> until they first hit the boundary, record the boundary value where each walk exits, and average those values to estimate <span class="math inline">\(h(x, y)\)</span>.</p>
<p>As a concrete example we‚Äôll take this <span class="math inline">\(7\times7\)</span> grid with radius <span class="math inline">\(3\)</span>:</p>
<div id="71529439" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === the rubber sheet boundary ===</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># -3 -2 -1  0  1  2  3</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># -3                 3</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># -3                 3</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># -3        x        3</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># -3                 3</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># -3                 3</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># -3 -2 -1  0  1  2  3</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>radius <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>boundary <span class="op">=</span> np.zeros((<span class="dv">2</span> <span class="op">*</span> radius <span class="op">+</span> <span class="dv">1</span>, <span class="dv">2</span> <span class="op">*</span> radius <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>boundary_horizontal <span class="op">=</span> np.arange(<span class="op">-</span>radius, radius <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>boundary[<span class="dv">0</span>, :] <span class="op">=</span> boundary_horizontal  <span class="co"># top edge</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>boundary[<span class="op">-</span><span class="dv">1</span>, :] <span class="op">=</span> boundary_horizontal  <span class="co"># bottom edge</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>boundary[:, <span class="dv">0</span>] <span class="op">=</span> <span class="op">-</span>radius  <span class="co"># left edge</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>boundary[:, <span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> radius  <span class="co"># right edge</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>center <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>boundary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>array([[-3., -2., -1.,  0.,  1.,  2.,  3.],
       [-3.,  0.,  0.,  0.,  0.,  0.,  3.],
       [-3.,  0.,  0.,  0.,  0.,  0.,  3.],
       [-3.,  0.,  0.,  0.,  0.,  0.,  3.],
       [-3.,  0.,  0.,  0.,  0.,  0.,  3.],
       [-3.,  0.,  0.,  0.,  0.,  0.,  3.],
       [-3., -2., -1.,  0.,  1.,  2.,  3.]])</code></pre>
</div>
</div>
<p>By symmetry the true centre value is <span class="math inline">\(0\)</span>. Let‚Äôs see how close a limited Monte-Carlo simulation gets to the true value. First we set up the random-walk sampler that returns the height of the exit cell:</p>
<div id="a7232a74" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> enum <span class="im">import</span> Enum, auto</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Direction(Enum):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    UP <span class="op">=</span> auto()</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    DOWN <span class="op">=</span> auto()</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    LEFT <span class="op">=</span> auto()</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    RIGHT <span class="op">=</span> auto()</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>MOVE_VECTORS <span class="op">=</span> {</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    Direction.UP: (<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    Direction.DOWN: (<span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    Direction.LEFT: (<span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>),</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    Direction.RIGHT: (<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> not_on_boundary(i, j, n_rows, n_cols):</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> i <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> i <span class="op">&lt;</span> n_rows <span class="op">-</span> <span class="dv">1</span> <span class="kw">and</span> j <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> j <span class="op">&lt;</span> n_cols <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> single_walk(grid, start_point, rng):</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    directions <span class="op">=</span> <span class="bu">list</span>(Direction)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    i, j <span class="op">=</span> start_point</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    n_rows, n_cols <span class="op">=</span> grid.shape</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> not_on_boundary(i, j, n_rows, n_cols):</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        direction <span class="op">=</span> rng.choice(directions)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        di, dj <span class="op">=</span> MOVE_VECTORS[direction]</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        i <span class="op">+=</span> di</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        j <span class="op">+=</span> dj</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> grid[i, j]</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> monte_carlo_rubber_sheet(grid, point, n_samples, rng):</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [single_walk(grid, point, rng) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_samples)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And now run and average the samples:</p>
<div id="a5d35139" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(<span class="dv">0</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> monte_carlo_rubber_sheet(boundary, center, n_samples, rng)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MC estimate after </span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss"> samples: </span><span class="sc">{</span><span class="bu">sum</span>(samples)<span class="op">/</span>n_samples<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>MC estimate after 1000 samples: 0.017</code></pre>
</div>
</div>
<p>This is an okay approximation. Note that for Monte Carlo, 1000 runs is not much as it‚Äôs inherently slow. One way to assess the quality of the method is by examining the <em>standard error</em>, which is the standard deviation of the estimator itself, i.e., the Monte Carlo simulation considered as a random variable (for a fixed sample size <span class="math inline">\(n\)</span>). We can see the standard error of this estimator in action if we run the upper experiment a couple of times. It‚Äôs quite high, so the estimates fluctuate a lot.</p>
<div id="4296856a" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> monte_carlo_rubber_sheet(boundary, center, n_samples, rng)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"MC estimate after </span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss"> samples: </span><span class="sc">{</span><span class="bu">sum</span>(samples)<span class="op">/</span>n_samples<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>MC estimate after 1000 samples: -0.039
MC estimate after 1000 samples: -0.006
MC estimate after 1000 samples: -0.032
MC estimate after 1000 samples: -0.045
MC estimate after 1000 samples: 0.058</code></pre>
</div>
</div>
<p>What I mean by ‚ÄòMonte Carlo is slow‚Äô is that the standard error typically scales with <span class="math inline">\(1/\sqrt{n}\)</span>. That is, if we want to cut the standard error in half, we have to run four times more simulations. I go more into detail about this in appendix <a href="#sec-mc-is-slow" class="quarto-xref"><span>Section 5.8.1</span></a>.</p>
<p>There are two final remarks I want to make about Monte Carlo in general:</p>
<ul>
<li>A single value without error bounds is usually not really usable. A simple way to get a priori assurances is using confidence intervals. I discuss them quickly in the appendix <a href="#sec-confidence-intervals" class="quarto-xref"><span>Section 5.8.2</span></a>.</li>
<li>A clever way to decrease the standard error is by importance sampling, which will is also crucial for off-policy learning discussed in <a href="#sec-off-policy-prediction-via-importance-sampling" class="quarto-xref"><span>Section 5.5</span></a>.</li>
</ul>
</div>
</section>
<section id="monte-carlo-estimation-of-action-values" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="monte-carlo-estimation-of-action-values"><span class="header-section-number">5.2</span> Monte Carlo Estimation of Action Values</h2>
<p>One way to estimate the action-values is to view each state as its own little armed-bandit where we choose one action and obtain a reward according to the policy. For this we would need exploring starts, the ability to start the episode in any state action pair. This view misses one point though, that by generating an episode starting from one given state-action pair we see the rewards for all state-action pairs that follow.</p>
<div id="exr-5.3" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.3</strong></span> What is the backup diagram for Monte Carlo estimation of <span class="math inline">\(q_\pi\)</span>?</p>
</div>
<div id="sol-5.3" class="proof solution">
<p><span class="proof-title"><em>Solution 5.3</em>. </span>I‚Äôm not 100% sure about this one. I think it‚Äôs just the backup diagram for <span class="math inline">\(v_\pi\)</span> but starting at an action node. The unsure part for me is that <span class="math inline">\(q_\pi\)</span> depends on an action and a state, so the state must be understood implicitly in the backup diagram. We could also demand that theoretically the actions for each state are distinct.</p>
<div class="text-center">
<img src="05-monte-carlo-methods_files/mediabag/da2c8a9eb28ccb7de3380b5d5fd1167a5379c61c.svg" class="img-fluid">
</div>
</div>
</section>
<section id="monte-carlo-control" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="monte-carlo-control"><span class="header-section-number">5.3</span> Monte Carlo Control</h2>
<p>Here is the algorithm for the first-visit Monte Carlo control algorithm with exploring starts</p>
<div id="lst-mc-control-exploring-starts-first-visit" class="listing-block listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-mc-control-exploring-starts-first-visit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;5.2: Monte Carlo ES (Exploring Starts), for estimating <span class="math inline">\(\pi \approx \pi_\ast\)</span>
</figcaption>
<div aria-describedby="lst-mc-control-exploring-starts-first-visit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="line-block"><strong>Initialisation</strong>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\pi(s) \in \mathcal{A}(s)\)</span>, for all <span class="math inline">\(s \in \mathcal{S}\)</span> arbitrarily<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(Q(s,a) \in \mathbb{R}\)</span>, for all <span class="math inline">\(s \in \mathcal{S}, a \in \mathcal{A}(s)\)</span> arbitrarily<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\mathrm{Returns}(s,a) \gets \mathrm{empty list}\)</span>, for all <span class="math inline">\(s \in \mathcal{S}, a \in \mathcal{A}(s)\)</span><br>
<br>
Loop forever:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Choose <span class="math inline">\(S_0 \in \mathcal{S}, A_0 \in \mathcal{A}(S_0)\)</span> randomly such that all pairs have probability <span class="math inline">\(&gt; 0\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;Generate an episode following <span class="math inline">\(\pi\)</span>: <span class="math inline">\(S_0,A_0, R_1, S_1, A_1, \dots, R_T, S_T\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(G \gets 0\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;Loop for each step of episode, <span class="math inline">\(t = T-1, T-2, \dots, 0\)</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(G \gets \gamma G + R_{t+1}\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If <span class="math inline">\((S_t, A_t) \not\in \{(S_0,A_0), \dots, (S_{t-1},A_{t-1})\}\)</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Append <span class="math inline">\(G\)</span> to <span class="math inline">\(\mathrm{Returns}(S_t,A_t)\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(Q(S_t,A_t) \gets \mathrm{average}(\mathrm{Returns}(S_t,A_t))\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\pi(S_t) \gets \arg \max_a Q(S_t,a)\)</span></div>
</div>
</figure>
</div>
<p>It‚Äôs actually quite ingenious how this algorithm circumvents the problem that MC prediction <a href="06-temporal-difference-learning.html#lst-mc-prediction-first-visit" class="quarto-xref">Listing&nbsp;<span>6.1</span></a> does not terminate, by letting the approximate <span class="math inline">\(Q\)</span> be a blend of all returns from all policies the algorithm has passed through so far. On the other hand, in my experience this algorithm tends to live in asymptopia‚Äîit can take an unpractical large number of episodes to converge to the optimal policy. In the practical world it can also result in rather flip-floppy behaviour. For example, in <a href="#exm-5.3-solving-black-jack" class="quarto-xref">Example&nbsp;<span>5.3</span></a> there are actions with low signal-to-noise ratios: their <span class="math inline">\(q\)</span>-values are close and have high variance. In this case the algorithm will often switch rapidly between these action values. It will eventually, in the limit‚Äîwhenever that may be‚Äîsettle on the correct one, but for solving Blackjack I couldn‚Äôt get there by sheer brute force. For obtaining good enough policies this is not a real problem‚Äîwhen the <span class="math inline">\(q\)</span>-values are close, it is largely unimportant which one gets chosen.</p>
<p>The general method also suffers from the usual problems that come with MC methods. When should we stop? How do we know that we have enough episodes? This is a substantial question in its own right, but we‚Äôre dealing with the foundations here, so we‚Äôll leave it for now.</p>
<div id="exr-5.4" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.4</strong></span> The pseudocode for Monte Carlo ES is inefficient because, for each state-action pair, it maintains a list of all returns and repeatedly calculates their mean. It would be more efficient to use techniques similar to those explained in Section 2.4 to maintain just the mean and a count (for each state‚Äìaction pair) and update them incrementally. Describe how the pseudocode would be altered to achieve this.</p>
</div>
<div id="sol-5.4" class="proof solution">
<p><span class="proof-title"><em>Solution 5.4</em>. </span>In the initialsation we don‚Äôt need <span class="math inline">\(\mathrm{Returns}\)</span> any more and use instead</p>
<div class="listing-block">
<div class="line-block">&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\mathrm{Count}(s,a) \gets 0\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\mathrm{Avg}(s,a) \gets 0.0\)</span></div>
</div>
<p>and in the last lines instead of appending <span class="math inline">\(G\)</span> to <span class="math inline">\(\mathrm{Returns}\)</span> and calculate the average we do this</p>
<div class="listing-block">
<div class="line-block">&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\mathrm{Count}(S_t,A_t) \gets \mathrm{Count}(S_t,A_t) + 1\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\mathrm{Avg}(S_t,A_t) \gets \mathrm{Avg}(S_t,A_t) + \frac{G - \mathrm{Avg}(S_t,A_t)}{\mathrm{Count}(S_t,A_t)}\)</span></div>
</div>
<p><br></p>
</div>
<div id="exm-5.3-solving-black-jack" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.3</strong></span> This is example 5.3: Solving Blackjack from <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span>.</p>
<p>Now, we attempt to find the optimal policy for blackjack from <a href="#exm-5.1-blackjack" class="quarto-xref">Example&nbsp;<span>5.1</span></a>. Spoiler alert: we won‚Äôt find it here. Using crude Monte Carlo methods would require an unreasonable huge amount of runs to find the optimal strategy. What we can do, however, is find a good strategy and discuss how to verify the optimal strategy from <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span>.</p>
<p>Let‚Äôs dive into the implementation. The code is nearly a verbatim copy of the algorithm given in <a href="#lst-mc-control-exploring-starts-first-visit" class="quarto-xref">Listing&nbsp;<span>5.2</span></a>, with two changes:</p>
<ul>
<li>the code uses the changes from <a href="#exr-5.4" class="quarto-xref">Exercise&nbsp;<span>5.4</span></a> for updating the averages of the <span class="math inline">\(Q\)</span>-values.</li>
<li>the code uses every-visit Monte Carlo, unlike the algorithm which is given for first-visit Monte Carlo. However, this doesn‚Äôt matter here as Blackjack is acyclic.</li>
</ul>
<div id="3747d658" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scripts.environment.black_jack <span class="im">as</span> black_jack</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_episode_es(env, œÄ, start_state, start_action):</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Generate an episode starting from start_state and start_action following policy œÄ."""</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    states <span class="op">=</span> [start_state]  <span class="co"># S_0, ..., S_T</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    rewards <span class="op">=</span> [env.set_state(start_state)]  <span class="co"># R_0, ..., R_T</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    actions <span class="op">=</span> [start_action]  <span class="co"># A_0, ..., A_{T-1}</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># take start action</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    state, reward, terminated <span class="op">=</span> env.step(start_action)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    states.append(state)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    rewards.append(reward)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># follow policy</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> terminated:</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        action <span class="op">=</span> œÄ[state]</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        actions.append(action)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        state, reward, terminated <span class="op">=</span> env.step(action)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        states.append(state)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>        rewards.append(reward)</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> states, rewards, actions</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mc_es(env, n_episodes, rng):</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Monte Carlo control with Exploring Starts.</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a><span class="co">        œÄ: The learned policy.</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a><span class="co">        q: The learned action-value function.</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>    env.rng <span class="op">=</span> rng</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>    q <span class="op">=</span> {</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>        (state, action): rng.random()</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> state <span class="kw">in</span> env.state_space</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> action <span class="kw">in</span> env.action_space</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>    œÄ <span class="op">=</span> {</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>        state: <span class="bu">max</span>(env.action_space, key<span class="op">=</span><span class="kw">lambda</span> action: q[(state, action)])</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> state <span class="kw">in</span> env.state_space</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>    }  <span class="co"># this essentially chooses œÄ randomly</span></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>    c <span class="op">=</span> {(state, action): <span class="dv">0</span> <span class="cf">for</span> state <span class="kw">in</span> env.state_space <span class="cf">for</span> action <span class="kw">in</span> env.action_space}</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_episodes):</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># make an episode</span></span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>        start_state <span class="op">=</span> rng.choice(env.state_space)</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>        start_action <span class="op">=</span> rng.choice(env.action_space)</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>        states, rewards, actions <span class="op">=</span> generate_episode_es(</span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>            env, œÄ, start_state, start_action</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># every visit</span></span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>        G <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>        state_actions <span class="op">=</span> [(states[i], actions[i]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(actions))]</span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(<span class="bu">len</span>(actions))):</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a>            G <span class="op">+=</span> rewards[i <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a>            sa <span class="op">=</span> state_actions[i]</span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a>            <span class="co"># update q</span></span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a>            c[sa] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a>            q[sa] <span class="op">+=</span> (G <span class="op">-</span> q[sa]) <span class="op">/</span> c[sa]</span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a>            <span class="co"># update œÄ</span></span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a>            state <span class="op">=</span> sa[<span class="dv">0</span>]</span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a>            œÄ[state] <span class="op">=</span> <span class="bu">max</span>(env.action_space, key<span class="op">=</span><span class="kw">lambda</span> a: q[(state, a)])</span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> œÄ, q</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>So let‚Äôs run it!</p>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>iterations <span class="op">=</span> <span class="dv">1_000_000</span>  <span class="co"># should be 1,000,000</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> random.Random(<span class="dv">0</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> black_jack.BlackJack()</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>œÄ, q <span class="op">=</span> mc_es(env, iterations, rng)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Plotting ---</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>player_totals <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">21</span>, <span class="dv">11</span>, <span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>dealer_showing <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">12</span>))</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Cell text</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>action_to_string <span class="op">=</span> {black_jack.Action.HIT: <span class="st">"H"</span>, black_jack.Action.STICK: <span class="st">"S"</span>}</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>cell_text_ace, cell_text_no_ace <span class="op">=</span> [], []</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> pt <span class="kw">in</span> player_totals:</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> [action_to_string[œÄ[black_jack.State(pt, <span class="va">True</span>, dc)]] <span class="cf">for</span> dc <span class="kw">in</span> dealer_showing]</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    cell_text_ace.append(row)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> [</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        action_to_string[œÄ[black_jack.State(pt, <span class="va">False</span>, dc)]] <span class="cf">for</span> dc <span class="kw">in</span> dealer_showing</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    cell_text_no_ace.append(row)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Cell colours</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>action_to_facecolor <span class="op">=</span> {<span class="st">"S"</span>: <span class="st">"#c6dbef"</span>, <span class="st">"H"</span>: <span class="st">"#fdd0a2"</span>}</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>cell_colours_ace <span class="op">=</span> [</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    [action_to_facecolor[element] <span class="cf">for</span> element <span class="kw">in</span> row] <span class="cf">for</span> row <span class="kw">in</span> cell_text_ace</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>cell_colours_no_ace <span class="op">=</span> [</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>    [action_to_facecolor[element] <span class="cf">for</span> element <span class="kw">in</span> row] <span class="cf">for</span> row <span class="kw">in</span> cell_text_no_ace</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>colWidths <span class="op">=</span> [<span class="dv">1</span> <span class="op">/</span> <span class="dv">25</span>] <span class="op">*</span> <span class="dv">10</span></span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>scale <span class="op">=</span> <span class="fl">1.5</span></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">8</span>))</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>fig.suptitle(<span class="ss">f"MC control Blackjack strategy</span><span class="ch">\n</span><span class="ss">(after </span><span class="sc">{</span>iterations<span class="sc">:,}</span><span class="ss"> iterations)"</span>)</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a><span class="co"># With Ace</span></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>ax1.set_axis_off()</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>tbl1 <span class="op">=</span> ax1.table(</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>    cellText<span class="op">=</span>cell_text_ace,</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>    cellColours<span class="op">=</span>cell_colours_ace,</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>    colWidths<span class="op">=</span>colWidths,</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    rowLabels<span class="op">=</span>player_totals,</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>    colLabels<span class="op">=</span>dealer_showing,</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>    loc<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>    cellLoc<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>tbl1.scale(scale, scale)</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">"Usable Ace"</span>)</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Without Ace</span></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>ax2.set_axis_off()</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>tbl2 <span class="op">=</span> ax2.table(</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>    cellText<span class="op">=</span>cell_text_no_ace,</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>    cellColours<span class="op">=</span>cell_colours_no_ace,</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>    colWidths<span class="op">=</span>colWidths,</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>    rowLabels<span class="op">=</span>player_totals,</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>    colLabels<span class="op">=</span>dealer_showing,</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>    loc<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>    cellLoc<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>tbl2.scale(scale, scale)</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">"No usable Ace"</span>)</span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-mc-control-blackjack" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-mc-control-blackjack-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="39e9ef04" class="cell" data-execution_count="11">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-11-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;5.3: This shows the policy found by MC control for Blackjack. The row labels show the player sum, the column label the dealer‚Äôs showing card, and the cells if the policy‚Äôs action is H(it) or S(tick)."><img src="05-monte-carlo-methods_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-mc-control-blackjack-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.3: This shows the policy found by MC control for Blackjack. The row labels show the player sum, the column label the dealer‚Äôs showing card, and the cells if the policy‚Äôs action is H(it) or S(tick).
</figcaption>
</figure>
</div>
<p>After 1 million episodes, we get a pretty good approximation of the optimal policy shown in Figure 5.2 from <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span>, but it‚Äôs not quite right. Smoothing out the kinks in the policy would require many more runs.</p>
<p>Even if we could run the code for much longer, there remains the question of how to ensure that the resulting policy <span class="math inline">\(\pi\)</span> is optimal. We could use Monte Carlo prediction to estimate the <span class="math inline">\(q\)</span>-values and then check if the policy takes only actions with the highest <span class="math inline">\(q\)</span>-values. However, how can we know if these values are accurate enough? For this, we need a statistical procedure to distinguish the means of action values, even if they are close to each other. Since Monte Carlo prediction can be viewed as a collection of armed bandits, we can use action elimination and stopping conditions for multi-armed bandits to obtain the optimal action. A good reference for the theoretical side can be found in <span class="citation" data-cites="eyal2006ActionElimination">Even-Dar, Mannor, and Mansour (<a href="#ref-eyal2006ActionElimination" role="doc-biblioref">2006</a>)</span>.</p>
<p>I‚Äôve done calculating and verifying the optimal solution in a side project, it‚Äôs the same given by <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span>. I won‚Äôt go into any more details though, as it‚Äôs only tangent to our aim for finding good policies for complicated environments.</p>
</div>
</section>
<section id="monte-carlo-control-without-exploring-starts" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="monte-carlo-control-without-exploring-starts"><span class="header-section-number">5.4</span> Monte Carlo Control without Exploring Starts</h2>
<p>Exploring starts has two problems:</p>
<ul>
<li>not always possible</li>
<li>explores all possible states-action pairs, even though optimal behaviour might only require exploring a small subset of them.</li>
</ul>
<p>And two ways to get exploration without exploring starts are:</p>
<ul>
<li>soft policies</li>
<li>off-policy prediction</li>
</ul>
<p>We discuss soft policies now and off-policy prediction in the next section <a href="#sec-off-policy-prediction-via-importance-sampling" class="quarto-xref"><span>Section 5.5</span></a>.</p>
<p>A policy is <span class="math inline">\(\varepsilon\)</span>-soft if <span class="math inline">\(\pi(a|s) \geq \frac{\varepsilon}{\mathcal{A}(s)}\)</span> for all <span class="math inline">\(s \in \mathcal{S}\)</span> and <span class="math inline">\(a \in \mathcal{A}(s)\)</span>. The role of the deterministic policies in this class is taken by the <span class="math inline">\(\epsilon\)</span>-greedy policies, policies that are as deterministic as <span class="math inline">\(\varepsilon\)</span>-soft policies are allowed. We can think of them as deterministic policies behind a randomizer. With probability <span class="math inline">\(\varepsilon\)</span> the action gets randomly chosen and with probability <span class="math inline">\(1-\varepsilon\)</span> the deterministic action is taken. This gives every action a probability of <span class="math inline">\(\frac{\varepsilon}{|\mathcal{A}(s)|}\)</span> except the greedy action which has a probability of <span class="math inline">\(1 - \varepsilon + \frac{\varepsilon}{|\mathcal{A}(s)|}\)</span>.</p>
<p>Here is the algorithm for approximating an optimal <span class="math inline">\(\varepsilon\)</span>-soft policy.</p>
<div id="lst-mc-control-on-policy-first-visit" class="listing-block listing quarto-float quarto-figure quarto-figure-left anchored">
<figure class="quarto-float quarto-float-lst figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-lst" id="lst-mc-control-on-policy-first-visit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Listing&nbsp;5.3: On-policy first-visit MC control (for <span class="math inline">\(\epsilon\)</span>-soft policies), estimates <span class="math inline">\(\pi \approx \pi_*\)</span>.
</figcaption>
<div aria-describedby="lst-mc-control-on-policy-first-visit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="line-block"><strong>Input</strong>: small <span class="math inline">\(\varepsilon &gt; 0\)</span><br>
<strong>Initialisation</strong>: <span class="math inline">\(\pi \gets\)</span> an arbitrary <span class="math inline">\(\varepsilon\)</span>-soft policy<br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(Q(s,a) \in \mathbb{R}\)</span> (arbitrarily), for all <span class="math inline">\(s \in \mathcal{S}\)</span>, <span class="math inline">\(a \in \mathcal{A}(s)\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\mathrm{Returns}(s,a) \gets\)</span> empty list, for all <span class="math inline">\(s \in \mathcal{S}\)</span>, <span class="math inline">\(a \in \mathcal{A}(s)\)</span><br>
<br>
Loop forever:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Generate an episode following <span class="math inline">\(\pi\)</span>: <span class="math inline">\(S_0,A_0, R_1, S_1, A_1, \dots, R_T, S_T\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(G \gets 0\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;Loop for each step of episode, <span class="math inline">\(t = T-1, T-2, \dots, 0\)</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(G \gets \gamma G + R_{t+1}\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If <span class="math inline">\((S_t,A_t)\)</span> is not in <span class="math inline">\(\{(S_0,A_0), \dots, (S_{t-1},A_{t-1})\}\)</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Append <span class="math inline">\(G\)</span> to <span class="math inline">\(\mathrm{Returns}(S_t)\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(Q(S_t, A_t) \gets \mathrm{average}(\mathrm{Returns}(S_t,A_t))\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(A^* \gets \arg\max_{a} Q(S_t,a)\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For all <span class="math inline">\(a \in \mathcal{A}(S_t)\)</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\pi(a|S_t) \gets \begin{cases} 1 - \varepsilon + \varepsilon/|\mathcal{A}(S_t)| \\ \varepsilon/|\mathcal{A}(S_t)| \end{cases}\)</span></div>
</div>
</figure>
</div>
<p>We will use this algorithm for <a href="#exr-5.12" class="quarto-xref">Exercise&nbsp;<span>5.12</span></a> and also discuss some properties of optimal <span class="math inline">\(\varepsilon\)</span>-soft policies.</p>
</section>
<section id="sec-off-policy-prediction-via-importance-sampling" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="sec-off-policy-prediction-via-importance-sampling"><span class="header-section-number">5.5</span> Off-policy Prediction via Importance Sampling</h2>
<p>Let‚Äôs try to motivate importance sampling and also see where the word ‚Äòimportance‚Äô comes from through the rubber sheet problem.</p>
<section id="importance-sampling-for-the-rubber-sheet-problem" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="importance-sampling-for-the-rubber-sheet-problem"><span class="header-section-number">5.5.1</span> üóê Importance Sampling for the Rubber Sheet Problem</h3>
<p>Let‚Äôs return to <a href="#exm-soap-bubble" class="quarto-xref">Example&nbsp;<span>5.2</span></a>, where we first saw the rubber sheet problem. This time we solve it on the following <span class="math inline">\(3\times 15\)</span> grid. The goal is to estimate the height at the centre point (marked with an <span class="math inline">\(x\)</span>) using Monte Carlo (MC) simulation.</p>
<div id="4325d5ba" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === the long rubber sheet problem ===</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 1                 x                 1</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>radius_lanky <span class="op">=</span> <span class="dv">7</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>boundary_height <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>boundary_lanky <span class="op">=</span> np.zeros((<span class="dv">3</span>, <span class="dv">2</span> <span class="op">*</span> radius_lanky <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>boundary_lanky[<span class="dv">1</span>, <span class="dv">0</span>] <span class="op">=</span> boundary_height</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>boundary_lanky[<span class="dv">1</span>, <span class="dv">2</span> <span class="op">*</span> radius_lanky] <span class="op">=</span> boundary_height</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>center_lanky <span class="op">=</span> (<span class="dv">1</span>, radius_lanky)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Before running MC, we compute the exact value at the centre so we can judge the estimator‚Äôs accuracy. For the analytical derivation, see <a href="#sec-strip-problem" class="quarto-xref"><span>Section 5.8.3</span></a>:</p>
<div id="51b2d1b5" class="cell" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code-fold: true</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> g(i):</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> i <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">1</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> i <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">2</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="dv">4</span> <span class="op">*</span> g(i <span class="op">-</span> <span class="dv">1</span>) <span class="op">-</span> g(i <span class="op">-</span> <span class="dv">2</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The exact value at the center is </span><span class="sc">{</span>boundary_height<span class="op">/</span>g(radius_lanky)<span class="sc">:.6f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The exact value at the center is 0.000198</code></pre>
</div>
</div>
<p>MC performs poorly on this long, narrow strip. Almost every random walk hits the top or bottom boundary, and only very rarely does one reach the left or right boundary. With <span class="math inline">\(1000\)</span> simulation, the best sample means we could see are:</p>
<ul>
<li><span class="math inline">\(0\)</span>, if all walks hit the top or bottom;</li>
<li><span class="math inline">\(1/1000=0.001\)</span>, if exactly one walk hits the left or right.</li>
</ul>
<p>The true value is about <span class="math inline">\(0.0002\)</span>. So even in the luckiest case, the estimator‚Äôs error is <span class="math inline">\(0.0002\)</span>.</p>
<p>So here is such a typical run:</p>
<div id="0dfa26b9" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(<span class="dv">0</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> monte_carlo_rubber_sheet(boundary_lanky, center_lanky, n_samples, rng)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="ss">f"MC estimate after </span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss"> samples: </span><span class="sc">{</span><span class="bu">sum</span>(samples)<span class="op">/</span>n_samples<span class="sc">}</span><span class="ss">"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>'MC estimate after 1000 samples: 0.0'</code></pre>
</div>
</div>
<p>Informally, the method is‚Äîif you‚Äôll excuse my anthropomorphising‚Äîbehaving as if it thought: ‚ÄúIt‚Äôs so unlikely I‚Äôll ever reach the side boundaries that I‚Äôll ignore them and just bounce between the top and bottom.‚Äù</p>
<p>But the left and right sides hold important information, while repeatedly sampling the top and bottom gives little new information. We can say that the left and right boundaries are important, and therefore it‚Äôs important to sample them more often.</p>
<p>This is the basic idea behind importance sampling: we know that some outcomes (or behaviours) should be sampled more frequently because they contribute more to the expectation we care about. However, if we do sample more frequently from these outcomes, we must correct for this bias in our final calculation.</p>
<p>Let‚Äôs formalise this for the rubber sheet problem above and bring it into the language of machine learning. We can see random walks on a grid as episodes of an MDP with a deterministic environment. An random walk is an episode <span class="math inline">\(\tau = S_0,A_0,\dots,S_{T-1},A_{T-1},S_T\)</span> (we are ignoring rewards for now), where the <span class="math inline">\(S_i\)</span> are the positions in the grid and the directions <span class="math inline">\(A_i\)</span> the chosen actions <span class="math inline">\(U,D,L,R\)</span>. <span class="math inline">\(S_0\)</span> is the center position and <span class="math inline">\(T\)</span> is the time of first exist and thus <span class="math inline">\(S_T\)</span> is the first boundary state.</p>
<p>We get equidirectional random walks from the uniform random policy <span class="math inline">\(\pi\)</span> that assigns equal probability to all directions <span class="math inline">\(\pi(U) = \pi(D) = \pi(L) = \pi(R) = 0.25\)</span> independent of the position. The probability of a particular trajectory <span class="math inline">\(\tau\)</span> under <span class="math inline">\(\pi\)</span> is independent of the <span class="math inline">\(S_i\)</span> as the environment is deterministic and the policy is also independent of the state <span class="math display">\[
\mathrm{Pr}_{\pi}(\tau) = \pi(A_0) \cdot \dots \cdot \pi(A_{T-1}).
\]</span></p>
<p>The expected exit height is therefore <span class="math display">\[
\mathbb{E}_{\tau \sim \pi}[h(\tau)] = \sum_{\tau} h(\tau) \cdot \mathrm{Pr}_{\pi}(\tau)
\]</span> where <span class="math inline">\(h(\tau) = h(S_T)\)</span>.</p>
<p>Now, instead of the target policy <span class="math inline">\(\pi\)</span>, suppose we sample using a behaviour policy <span class="math inline">\(b\)</span> which prefers left and right (and is also independent of the states): <span class="math display">\[
b(R) = b(L) = 0.45, \quad b(U) = b(D) = 0.05.
\]</span></p>
<p>How can we use episodes sampled according to <span class="math inline">\(b\)</span> to estimate <span class="math inline">\(\mathbb{E}_{\tau \sim \pi_t}[h(\tau)]\)</span>? We can use a clever trick here: <span class="math display">\[
\begin{split}
\mathbb{E}_{\tau \sim \pi}[h(\tau)] &amp;= \sum_{\tau} h(\tau) \mathrm{Pr}_{\pi}(\tau) \\
&amp;= \sum_{\tau} h(\tau) \frac{\mathrm{Pr}_\pi(\tau)}{\mathrm{Pr}_b(\tau)} \cdot \mathrm{Pr}_b(\tau) \\
&amp;= \mathbb{E}_{\tau \sim b}\left[h(\tau) \frac{\mathrm{Pr}_\pi(\tau)}{\mathrm{Pr}_b(\tau)}\right]
\end{split}
\]</span></p>
<p>A simple unbiased estimator given <span class="math inline">\(n\)</span> samples <span class="math inline">\(\tau_i \sim b\)</span> is <span class="math display">\[
\frac{1}{n}\sum h(\tau_i)w(\tau_i) \quad \text{where } w(\tau_i) = \frac{\pi_t(\tau_i)}{\pi_b(\tau_i)}
\]</span> where <span class="math inline">\(w(\tau)\)</span> is called the importance weight.</p>
<p>Now, let‚Äôs implement importance sampling. First we define a function that returns <span class="math inline">\(h(\tau)w(\tau)\)</span> for one episode following <span class="math inline">\(b\)</span>:</p>
<div id="2c5979f4" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === importance sampling single episode ===</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> single_walk_importance_sampling(</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    grid,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    start_point,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    b: <span class="bu">dict</span>[Direction, <span class="bu">float</span>],</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    rng,</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Sample œÑ under `b` and return h(œÑ)¬∑w(œÑ)</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co">    for uniform target œÄ(a)=0.25.</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    directions <span class="op">=</span> <span class="bu">list</span>(b.keys())</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> <span class="bu">list</span>(b.values())</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># per-action ratios œÄ(a) / b(a); here œÄ(a) = 0.25</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    direction_ratio <span class="op">=</span> {directions[i]: <span class="fl">0.25</span> <span class="op">/</span> probs[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(b))}</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    i, j <span class="op">=</span> start_point</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    n_rows, n_cols <span class="op">=</span> grid.shape</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    importance_weight <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># walk until a boundary cell is reached</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> not_on_boundary(i, j, n_rows, n_cols):</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># sample an action according to b</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>        direction <span class="op">=</span> rng.choice(directions, p<span class="op">=</span>probs)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># move on grid</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>        di, dj <span class="op">=</span> MOVE_VECTORS[direction]</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>        i <span class="op">+=</span> di</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>        j <span class="op">+=</span> dj</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>        importance_weight <span class="op">*=</span> direction_ratio[direction]</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># on exit, grid[i, j] = h(s_T)</span></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> importance_weight <span class="op">*</span> grid[i, j]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can sample some values and take the average to get an estimate:</p>
<div id="5067085b" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === importance sampling for the long rubber sheet ===</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(<span class="dv">0</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> {</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    Direction.RIGHT: <span class="fl">0.45</span>,</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    Direction.LEFT: <span class="fl">0.45</span>,</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    Direction.UP: <span class="fl">0.05</span>,</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    Direction.DOWN: <span class="fl">0.05</span>,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> [</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    single_walk_importance_sampling(boundary_lanky, center_lanky, b, rng)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_samples)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"importance sampling after </span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss"> iterations:"</span>)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.average(samples))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>importance sampling after 1000 iterations:
0.0001407157859082321</code></pre>
</div>
</div>
<p>We can see that importance sampling MC performs better than ‚Äòcrude‚Äô MC‚Äîas a simple MC is called in contrast to importance sampling MC. Importance sampling MC has an error of about <span class="math inline">\(0.00006\)</span> compared to the <span class="math inline">\(0.0002\)</span> from the crude MC before. And generally, we can expect better results from the importance sampling MC due to its lower variance.</p>
<p>The error of MC techniques depends only on two factors‚Äîthe standard deviation <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(1/\sqrt{n}\)</span> (under the normal approximation that holds for large sample numbers). Importance sampling is a variance reduction technique that gives us an improvement in our estimates without driving up the simulation costs. We can compare the two variances of crude MC and importance sampling for our example:</p>
<div id="ee8d4c77" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1</span>  <span class="co"># todo: 100_000</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># crude</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(seed)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>samples_crude <span class="op">=</span> monte_carlo_rubber_sheet(boundary_lanky, center_lanky, n_samples, rng)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>œÉ_crude <span class="op">=</span> np.std(samples_crude)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co"># importance sampling</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(seed)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>samples_is <span class="op">=</span> [</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    single_walk_importance_sampling(boundary_lanky, center_lanky, b, rng)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_samples)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>œÉ_is <span class="op">=</span> np.std(samples_is)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimates for œÉ after </span><span class="sc">{</span>n_samples<span class="sc">:,}</span><span class="ss"> iterations"</span>)</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"crude Monte Carlo œÉ: </span><span class="sc">{œÉ</span>_crude<span class="sc">:.5f}</span><span class="ss">"</span>)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"importance sampling œÉ: </span><span class="sc">{œÉ</span>_is<span class="sc">:.5f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Estimates for œÉ after 1 iterations
crude Monte Carlo œÉ: 0.00000
importance sampling œÉ: 0.00000</code></pre>
</div>
</div>
<p>So we get a roughly <span class="math inline">\(10\times\)</span> boost in our accuracy, just by sampling more the important directions.</p>
</section>
<section id="importance-sampling-in-ml" class="level3" data-number="5.5.2">
<h3 data-number="5.5.2" class="anchored" data-anchor-id="importance-sampling-in-ml"><span class="header-section-number">5.5.2</span> üóê Importance Sampling in ML</h3>
<p>After this little detour of importance sampling in statistics, let‚Äôs talk about how it shows up in ML for off-policy prediction. The goal here isn‚Äôt variance reduction at all; it‚Äôs to let us evaluate a target policy using data generated by a different behaviour policy. In fact, the variance can easily blow up to infinity.</p>
<p>Suppose we have a behaviour policy <span class="math inline">\(b\)</span>, which we use to generate episodes, and a target policy <span class="math inline">\(\pi\)</span>, for which we want the expected return <span class="math inline">\(v_\pi(s)\)</span>. As before, we can pull out the importance sampling trick: <span class="math display">\[
\begin{split}
v_\pi(s) &amp;= \mathbb{E}_{\tau \sim \pi}[G_0(\tau)| S_0 = s] \\
&amp;= \sum_{\tau} G_0(\tau) \mathrm{Pr}_{\pi}(\tau|S_0 = s) \\
&amp;= \sum_{\tau} G_0(\tau) \frac{\mathrm{Pr}_\pi(\tau |S_0 = s)}{\mathrm{Pr}_b(\tau|S_0 = s)} \mathrm{Pr}_b(\tau|S_0 = s) \\
&amp;= \mathbb{E}_{\tau \sim b}\left[G_0(\tau) \frac{\mathrm{Pr}_\pi(\tau|S_0 = s)}{\mathrm{Pr}_b(\tau|S_0 = s)}\Big| S_0 = s\right]
\end{split}
\]</span></p>
<p>We call the ratio inside the expectation the <em>importance weight</em>: <span class="math display">\[
w(\tau) = \frac{\mathrm{Pr}_\pi(\tau|S_0 = s)}{\mathrm{Pr}_b(\tau|S_0=s)}.
\]</span></p>
<p>Let‚Äôs compute <span class="math inline">\(w(\tau)\)</span> for an episode <span class="math inline">\(\tau = S_0, A_0, \dots, A_{T-1}, R_T, S_T\)</span>. First note that <span class="math display">\[
\mathrm{Pr}_\pi(\tau | S_0 = s) = \prod_{k=0}^{T-1} \pi(A_k|S_k) p(S_{k+1}| S_k, A_k)
\]</span> and equally for <span class="math inline">\(\mathrm{Pr}_\pi(\tau|S_0 = s)\)</span>. So the importance weight is <span class="math display">\[
\begin{split}
w(\tau) &amp;= \frac{\mathrm{Pr}_\pi(\tau|S_0 = s)}{\mathrm{Pr}_b(\tau|S_0 = s)} \\
&amp;= \prod_{k = 0}^{T-1}\frac{\pi(A_k|S_k)}{b(A_k|S_k)}
\end{split}
\]</span> All the environment dynamics <span class="math inline">\(p(\cdot)\)</span> cancel out, so the importance weight only depends on the policies which we can compute.</p>
<p>If we collect everything and generalise slightly, we can write: <span id="eq-importance-sampling-expectation"><span class="math display">\[
v_\pi(s) = \mathbb{E}_{\tau \sim b}[w_{t:}(\tau)G_t(\tau) | S_t = s]
\tag{5.3}\]</span></span></p>
<p>with <span id="eq-importance-weight"><span class="math display">\[
w_{t:}(\tau) = \prod_{k = t}^{T-1}\frac{\pi(A_k|S_k)}{b(A_k|S_k)}
\tag{5.4}\]</span></span></p>
<p>I‚Äôve drifted away from <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span> notation here‚Äîand I‚Äôll stick with it for now, because for me their notation is a bit dense. I know‚Ä¶ bold move.</p>
<p>Now let‚Äôs meet the estimators for <a href="#eq-importance-sampling-expectation" class="quarto-xref">Equation&nbsp;<span>5.3</span></a>. For episodes <span class="math inline">\(\tau^{(1)}, \tau^{(2)}, \dots, \tau^{(n)} \sim b\)</span> we define:</p>
<ul>
<li><strong>Ordinary importance sampling (OIS)</strong>: <span id="eq-ordinary-importance-sampling"><span class="math display">\[
V^{\mathrm{OIS}}(s) = \frac{\sum_{(i,t) \in \mathcal{T}(s)} w_{t:}(\tau^{(i)}) G_t(\tau^{(i)})}{|\mathcal{T}(s)|},
\tag{5.5}\]</span></span> where <span class="math inline">\(\mathcal{T}(s)\)</span> is either:
<ul>
<li><strong>first-visit:</strong> all <span class="math inline">\((i,t)\)</span> such that <span class="math inline">\(s\)</span> is first visited at time <span class="math inline">\(t\)</span> in episode <span class="math inline">\(i\)</span>, or</li>
<li><strong>every visit:</strong> all <span class="math inline">\((i, t)\)</span> such that <span class="math inline">\(S^{(i)}_t = s\)</span>.</li>
</ul></li>
<li><strong>Weighted importance sampling (WIS)</strong>: <span id="eq-weighted-importance-sampling"><span class="math display">\[
V^{\mathrm{WIS}}(s) = \frac{\sum_{(i,t) \in \mathcal{T}(s)} w_{t:}(\tau^{(i)}) G_t(\tau^{(i)})}{\sum_{(i,t) \in \mathcal{T}(s)} w_{t:}(\tau^{(i)})}.
\tag{5.6}\]</span></span> This also comes in first-visit and every-visit flavours.</li>
</ul>
</section>
<section id="bias-mse-and-all-that" class="level3" data-number="5.5.3">
<h3 data-number="5.5.3" class="anchored" data-anchor-id="bias-mse-and-all-that"><span class="header-section-number">5.5.3</span> üóê Bias, MSE, and All That</h3>
<p>Time to talk properly about estimators. An estimator is just a rule for computing an estimate of some unknown quantity from data. If you want, you can think of an estimator as a random variable built out of other random variables (your data).</p>
<p>In our case, the unknown quantity is <span class="math inline">\(v_\pi\)</span>, the true value function under the target policy <span class="math inline">\(\pi\)</span>; the data are the episodes <span class="math inline">\(\tau^{(1)}, \dots, \tau^{(n)}\)</span> generated under the behaviour policy <span class="math inline">\(b\)</span>; and the estimators are the various importance sampling constructions: ordinary vs weighted, and first-visit vs every-visit.</p>
<section id="first-visit-ordinary-importance-sampling" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="first-visit-ordinary-importance-sampling">First-Visit Ordinary importance Sampling</h4>
<p>The first-visit ordinary IS estimator, <span class="math inline">\(V_\mathrm{fv}^\mathrm{OIS}\)</span>, is probably the simplest of the lot. For a given state <span class="math inline">\(s\)</span>, we collect the first <span class="math inline">\(m\)</span> first-visit samples and treat them as i.i.d. pairs <span class="math inline">\((w_j,G_j)\)</span> of importance weights and returns. Then: <span class="math display">\[
V^{\mathrm{OIS}}_\text{fv}(s) = \frac{1}{m}\sum_{j=1}^m w_j G_j.
\]</span></p>
<p>Because it‚Äôs just the mean of independent samples, it‚Äôs <em>unbiased</em>: <span class="math display">\[
\mathrm{E}[V^{\mathrm{OIS}}_\text{fv}(s)] = v_\pi(s)
\]</span> basically by construction, since <span class="math display">\[
\mathbb{E}[w_jG_j] = v_\pi(s)
\]</span></p>
<p>A standard way of judging an estimator is the <em>mean squared error</em> (MSE): <span class="math display">\[
\mathrm{MSE}(V^{\mathrm{OIS}}_\text{fv}(s)) = \mathbb{E}[(\mathrm{V}^{OIS}_\text{fv}(s) - v_\pi(s))^2].
\]</span></p>
<p>For an unbiased estimator, the MSE is just the variance, so it scales like <span class="math inline">\(1/m\)</span> What we usually feel in practice is the root MSE (RMSE): <span class="math display">\[
\text{RMSE} = \sqrt{\text{MSE}},
\]</span> which gives the familiar Monte-Carlo rate: <span class="math inline">\(O(1/\sqrt{m})\)</span>.</p>
<p>The catch? Ordinary importance sampling can have infinite variance if the importance weights themselves have infinite variance‚Äîwhich can happen for both first-visit and every-visit versions (see <a href="#exm-5.5-infinite-variance" class="quarto-xref">Example&nbsp;<span>5.5</span></a> and the solution to <a href="#exr-5.8" class="quarto-xref">Exercise&nbsp;<span>5.8</span></a>). In those cases, you obviously don‚Äôt get the <span class="math inline">\(O(1/\sqrt{m})\)</span> behaviour. Convergence does still happen, but it becomes even slower and generally not usable.</p>
</section>
<section id="first-visit-weighted-importance-sampling" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="first-visit-weighted-importance-sampling">First-Visit Weighted importance Sampling</h4>
<p>Now let‚Äôs look at the first-visit weighted IS estimator: <span class="math display">\[
V_{\text{fv}}^{\mathrm{WIS}} = \frac{\sum_{j=1}^m w_j G_j}{\sum_{j=1} w_j},
\]</span> again for i.i.d. samples <span class="math inline">\((w_j,G_j)\)</span>. This estimator trades a little bias for lower variance, where bias is defined as: <span class="math display">\[
B(V_{\text{fv}}^{\mathrm{WIS}}) = \mathbb{E}[V_{\mathrm{fv}}^{\mathrm{WIS}}] - v_\pi(s),
\]</span></p>
<p>To see why the estimator is generally biased, write it as <span class="math display">\[
V_{\text{fv}}^{\mathrm{WIS}} = \frac{\left(\sum_{j=1}^m w_j G_j\right)/m}{\left(\sum_{j=1} w_j\right)/m},
\]</span> The numerator is <span class="math inline">\(V_{\text{fv}}^{\mathrm{OIS}}\)</span>, whose expectation is <span class="math inline">\(v_\pi(s)\)</span>; the denominator has expectation 1 (we‚Äôll show this in a moment). But because these two random variables are dependent, we can‚Äôt in general take the expectation through the quotient: <span class="math display">\[
\mathbb{E}[V_{\text{fv}}^{\mathrm{WIS}}] = \mathbb{E}\left[\frac{V_{\text{fv}}^{\mathrm{OIS}}}{(\sum_j w_j)/m}\right]
\not= \frac{\mathbb{E}[V_{\text{fv}}^{\mathrm{OIS}}]}{\mathbb{E}[(\sum_j w_j)/m]}
= \frac{v_\pi(s)}{1}
\]</span> And here is why <span class="math inline">\(\mathbb{E}[w]=1\)</span>: <span class="math display">\[
\begin{split}
\mathbb{E}_{\tau \sim b}[w] &amp;= \sum_{\tau} \frac{p_\pi(\tau|S_0=s)}{p_b(\tau)|S_0=s} p_b(\tau|S_0=s) \\
&amp;= \sum_{\tau} p_\pi(\tau|S_0=s) \\
&amp;= 1
\end{split}
\]</span></p>
<p>Despite the bias, it‚Äôs really not a disaster: the bias shrinks as <span class="math inline">\(1/m\)</span> <span class="citation" data-cites="agapiou2017Importance">(<a href="#ref-agapiou2017Importance" role="doc-biblioref">Agapiou et al. 2017</a>, Theorem 2.1)</span>, and the MSE shrinks as <span class="math inline">\(1/m\)</span> too, just as with OIS. So the bias isn‚Äôt doing any real harm.</p>
<p>A crucial advantage is that weighted IS always has finite variance as long as returns are bounded by some <span class="math inline">\(a\)</span> (maybe even if they are unbounded, I didn‚Äôt check that). We can write it as a convex combination: <span class="math display">\[
V^\mathrm{WIS}_\text{fv} = \sum_{j=1}^m \alpha_j G_j \quad \text{with } \alpha_j = \frac{w_j}{\sum_{k=1}^m w_k}
\]</span></p>
<p>Since the <span class="math inline">\(\alpha_j\)</span> just do a weighted sum of the <span class="math inline">\(‚à£G_j‚à£\leq a\)</span>, we have <span class="math inline">\(\mathbb{E}[(V^\mathrm{WIS}_\text{fv})^2] \leq a^2\)</span>.</p>
</section>
<section id="every-visit-importance-sampling" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="every-visit-importance-sampling">Every-Visit Importance Sampling</h4>
<p>The every-visit versions is maybe the easiest to come up conceptually. However, the pairs <span class="math inline">\((w_j,G_j)\)</span> are not independent when they come from the same episode. This creates correlations that complicate the variance analysis.</p>
<p>The good news is that the every-visit estimators are still consistent: <span class="math display">\[
V_\mathrm{ev}^\mathrm{OIS} \to v_œÄ(s), V_\mathrm{ev}^\mathrm{WIS} \to v_\pi(s) \quad \text{for } n \to \infty
\]</span></p>
<p>but they are no longer unbiased for finite data‚Äîeven for ordinary importance sampling. Practically, the every-visit estimators make fuller use of data: they reuse later parts of each episode instead of discarding everything after the first occurrence of a state. But I don‚Äôt know when this is actually useful.</p>
<div id="exr-5.5" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.5</strong></span> Consider an MDP with a single nonterminal state and a single action that transitions back to the nonterminal state with probability <span class="math inline">\(p\)</span> and transitions to the terminal state with probability <span class="math inline">\(1-p\)</span>. Let the reward be <span class="math inline">\(+1\)</span> on all transitions, and let <span class="math inline">\(\gamma = 1\)</span>. Suppose you observe one episode that lasts 10 steps, with a return of 10. What are the first-visit and every-visit estimators of the value of the nonterminal state?</p>
</div>
<div id="sol-5.5" class="proof solution">
<p><span class="proof-title"><em>Solution 5.5</em>. </span>The exercise itself is straightforward:</p>
<ul>
<li>The first-visit estimate is the first return: 10.</li>
<li>The every-visit estimate averages all returns after each visit to the state: <span class="math display">\[
\frac{10 + 9 + \dots + 1}{10} = \frac{10\cdot 11}{2 \cdot 10} = 5.5
\]</span></li>
</ul>
<p>That‚Äôs the basic part. Now let‚Äôs go a bit further and use this setup to show explicitly that the every-visit estimator <span class="math inline">\(V_{\text{ev}}(s)\)</span> is biased.</p>
<p>The episode length <span class="math inline">\(L\)</span> is geometrically distributed: <span class="math display">\[
\mathrm{Pr}(L = \ell) = p^{\ell-1}(1-p).
\]</span> The return of such an episode is just <span class="math inline">\(\ell\)</span>, so the true value of the nonterminal state is <span class="math display">\[
\begin{split}
v(s) &amp;= \sum_{\ell = 1}^\infty \ell \cdot p^{\ell -1}(1-p) \\
&amp;= (1-p) \left(\sum_{\ell = 1}^\infty p^\ell \right)' \\
&amp;= (1-p) \left( \frac{1}{1-p} \right)' \\
&amp;= \frac{1}{1-p}
\end{split}
\]</span></p>
<p>The every-visit estimator for a single episode of length <span class="math inline">\(L\)</span> is <span class="math display">\[
V_\text{ev} = \frac{1+\dots+L}{L} = \frac{L+1}{2}
\]</span> So <span class="math display">\[
\mathbb{E}(V_\text{ev}) = \sum_{\ell = 1}^\infty \frac{\ell + 1}{2} p^{\ell-1}(1-p) = \frac{2-p}{2(1-p)}.
\]</span> Thus the bias is <span class="math display">\[
B(V_\text{ev}) = \mathbb{E}(V_\text{ev}) - v = - \frac{1}{2} \frac{p}{1-p}.
\]</span> So we can see that the estimator is biased when sampling a single episode.</p>
<p>Now let‚Äôs go above and beyond and compute the bias for the general case of <span class="math inline">\(m\)</span> episodes. This is mainly to demonstrate how annoying it can be to work with data that aren‚Äôt i.i.d.</p>
<p>For <span class="math inline">\(m\)</span> episodes of lengths <span class="math inline">\(L_1,\dots,L_m\)</span>, the every-visit estimator is <span class="math display">\[
\begin{split}
V_\text{ev} &amp;= \frac{\sum_{i=1}^m \sum_{t=1}^{L_i} G_{i,t}}{\sum_{i=1}^m L_i} \\
&amp;= \frac{\sum_{i=1}^m \frac{L_i(L_i+1)}{2}}{\sum_{i=1}^m L_i} \\
&amp;= \frac{1}{2} \left( 1 + \frac{\sum_{i=1}^m L_i^2}{\sum_{i=1}^m L_i}\right),
\end{split}
\]</span></p>
<p>Let <span class="math inline">\(S_m=\sum_{i=1}^m L_i\)</span>. We now we rely on two non-trivial facts:</p>
<ul>
<li><span class="math inline">\(\mathbb{E}[L_1^2|S_m = s] = \frac{s(2s-m+1)}{m(m+1)}\)</span></li>
<li><span class="math inline">\(\mathbb{E}[S_m] = \frac{m}{1-p}\)</span>.</li>
</ul>
<p>Then <span class="math display">\[
\begin{split}
\mathbb{E}\left[ \frac{\sum_{i=1}^m L_i^2}{\sum_{i=1}^m L_i} \right] &amp;= \sum_{s = m}^\infty \mathbb{E}\left[ \frac{\sum_{i=1}^m L_i^2}{s} | S_m = s \right] \mathrm{Pr}(S_m = s) \\
&amp;= \sum_{s = m}^\infty \frac{m}{s}\mathbb{E}\left[ L_1^2 | S_m = s \right] \mathrm{Pr}(S_m = s) \\
&amp;= m\sum_{s = m}^\infty \frac{1}{s} \frac{s(2s-m+1)}{m(m+1)} \mathrm{Pr}(S_m = s) \\
&amp;= \frac{1}{m+1} \sum_{s=m}^\infty (2s-m+1) \mathrm{Pr}(S_m = s) \\
&amp;= \frac{1}{m+1}\mathbb{E}[2S_m - m + 1] \\
&amp;= \frac{1}{m+1}\left(\frac{2m}{1-p} - m + 1\right).
\end{split}
\]</span></p>
<p>Substituting this into the expression for <span class="math inline">\(\mathbb{E}[V_\text{ev}]\)</span> and simplifying gives: <span class="math display">\[
\mathbb{E}[V_\text{ev}] = \frac{m + 1 - p}{(m+1)(1-p)}.
\]</span> So the bias is <span class="math display">\[
B[V_\text{ev}] = -\frac{1}{m+1}\frac{p}{1-p}.
\]</span></p>
<p>Surprinsingly, this is a very straightforward generalisation of the <span class="math inline">\(m=1\)</span> case. Also the bias falls as <span class="math inline">\(1/m\)</span>.</p>
</div>
<div id="exm-5.4-off-policy-evaluation-black-jack" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.4</strong></span> This is example 5.4: <strong>Off-policy Estimation of a Blackjack State Value</strong> from <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span>.</p>
<p>Let‚Äôs use importance sampling for off-policy prediction for the first time. The goal is to estimate the value <span class="math inline">\(v_\pi(s)\)</span> of a specific Blackjack state under a target policy <span class="math inline">\(\pi\)</span>, even though our data will be generated by a behaviour policy <span class="math inline">\(b\)</span>. Concretely:</p>
<ul>
<li>MDP = blackjack</li>
<li><span class="math inline">\(\pi =\)</span> greedy policy from <a href="#exm-5.1-blackjack" class="quarto-xref">Example&nbsp;<span>5.1</span></a></li>
<li><span class="math inline">\(b =\)</span> uniform random policy</li>
<li><span class="math inline">\(s =\)</span> (player‚Äôs total = 13, usable ace = yes, dealer‚Äôs showing = 2)</li>
</ul>
<p><span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span> give the reference value <span class="math inline">\(v_\pi(s)=‚àí0.27726\)</span>. Let‚Äôs check it ourselves with crude Monte Carlo just to be sure:</p>
<div id="1696f9e7" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === crude MC estimate of blackjack state value ===</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_episode_from_state(env, œÄ, start_state):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Generate an episode starting from start_state following œÄ."""</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    env.set_state(start_state)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    state, terminated <span class="op">=</span> start_state, <span class="va">False</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> terminated:</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        action <span class="op">=</span> œÄ[state]</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        state, reward, terminated <span class="op">=</span> env.step(action)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> reward</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>env <span class="op">=</span> BlackJack()</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>start_state <span class="op">=</span> State(<span class="dv">13</span>, <span class="va">True</span>, <span class="dv">2</span>)</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">1</span>  <span class="co"># 100_000</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>trials <span class="op">=</span> [</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    generate_episode_from_state(env, œÄ_at_least_20, start_state)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_samples)</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"v_œÄ(s) ~= </span><span class="sc">{</span><span class="bu">sum</span>(trials) <span class="op">/</span> n_samples<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>n_samples<span class="sc">}</span><span class="ss"> trials)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>v_œÄ(s) ~= 1.0 (1 trials)</code></pre>
</div>
</div>
<p>This lands pretty close to <span class="math inline">\(-0.27726\)</span>, so we believe them and take their number as the reference.</p>
<p>Now let‚Äôs set up importance sampling. To do off-policy prediction we need to calculate the importance weight <a href="#eq-importance-weight" class="quarto-xref">Equation&nbsp;<span>5.4</span></a>. Because <span class="math inline">\(b\)</span> is stochastic and <span class="math inline">\(\pi\)</span> is deterministic, the importance weight for a trajectory is: <span class="math display">\[
w(\tau) = \begin{cases} 0 &amp; \text{if } \exists t \text{ s.t. } A_{t} \neq \pi(S_{t}) \\ \prod_{t=0}^{T-1}\frac{1}{b(A_t)} &amp; \text{otherwise} \end{cases}
\]</span></p>
<p>Here is the implementation of the function <code>bj_importance_weight_compliance</code> that generates an episode and returns the importance weight and the return. The behaviour policy <span class="math inline">\(b\)</span> is hardcoded as uniformly random and the target policy <span class="math inline">\(\pi\)</span> is a parameter and expects a deterministic policy. Since <span class="math inline">\(b\)</span> is stochastic and <span class="math inline">\(\pi\)</span> is deterministic, the importance weight is <span class="math inline">\(0\)</span> if <span class="math inline">\(b\)</span> does something <span class="math inline">\(\pi\)</span> wouldn‚Äôt. This results in a <em>compliance</em> version of importance sampling: as soon as the behaviour policy deviates from the target policy the resulting importance-weight is <span class="math inline">\(0\)</span>. That means in our case‚Äîwhere we have two actions and the behaviour policy is uniformly random‚Äîthe importance-weight is either <span class="math inline">\(0\)</span> if <span class="math inline">\(b\)</span> does something <span class="math inline">\(\pi\)</span> wouldn‚Äôt or <span class="math inline">\(2^\ell\)</span> where <span class="math inline">\(\ell\)</span> is the number of compliant actions.</p>
<div id="2a87d06e" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="annotated-cell-25"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-25-1"><a href="#annotated-cell-25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># === single importance-sampling episode for Black Jack ===</span></span>
<span id="annotated-cell-25-2"><a href="#annotated-cell-25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-25-3"><a href="#annotated-cell-25-3" aria-hidden="true" tabindex="-1"></a>EpisodeWG <span class="op">=</span> <span class="bu">tuple</span>[<span class="bu">float</span>, <span class="bu">float</span>]  <span class="co"># (weight, return)</span></span>
<span id="annotated-cell-25-4"><a href="#annotated-cell-25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-25-5"><a href="#annotated-cell-25-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-25-6"><a href="#annotated-cell-25-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bj_importance_weight_compliance(</span>
<span id="annotated-cell-25-7"><a href="#annotated-cell-25-7" aria-hidden="true" tabindex="-1"></a>    env: BlackJack, œÄ: <span class="bu">dict</span>[State, Action], start_state: State, rng</span>
<span id="annotated-cell-25-8"><a href="#annotated-cell-25-8" aria-hidden="true" tabindex="-1"></a>) <span class="op">-&gt;</span> EpisodeWG:</span>
<span id="annotated-cell-25-9"><a href="#annotated-cell-25-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Generate one episode under the *behaviour* policy b (uniform random)</span></span>
<span id="annotated-cell-25-10"><a href="#annotated-cell-25-10" aria-hidden="true" tabindex="-1"></a><span class="co">    and return (importance-weight, return)</span></span>
<span id="annotated-cell-25-11"><a href="#annotated-cell-25-11" aria-hidden="true" tabindex="-1"></a><span class="co">    for target deterministic policy œÄ.</span></span>
<span id="annotated-cell-25-12"><a href="#annotated-cell-25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-25-13"><a href="#annotated-cell-25-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Note:</span></span>
<span id="annotated-cell-25-14"><a href="#annotated-cell-25-14" aria-hidden="true" tabindex="-1"></a><span class="co">    If the behaviour policy deviates even once (non-compliant),</span></span>
<span id="annotated-cell-25-15"><a href="#annotated-cell-25-15" aria-hidden="true" tabindex="-1"></a><span class="co">    the correct IS weight is 0 and this returns (0, 0)."""</span></span>
<span id="annotated-cell-25-16"><a href="#annotated-cell-25-16" aria-hidden="true" tabindex="-1"></a>    env.rng <span class="op">=</span> rng</span>
<span id="annotated-cell-25-17"><a href="#annotated-cell-25-17" aria-hidden="true" tabindex="-1"></a>    env.set_state(start_state)</span>
<span id="annotated-cell-25-18"><a href="#annotated-cell-25-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-25-19"><a href="#annotated-cell-25-19" aria-hidden="true" tabindex="-1"></a>    episode_length <span class="op">=</span> <span class="dv">0</span></span>
<span id="annotated-cell-25-20"><a href="#annotated-cell-25-20" aria-hidden="true" tabindex="-1"></a>    state, terminated <span class="op">=</span> start_state, <span class="va">False</span></span>
<span id="annotated-cell-25-21"><a href="#annotated-cell-25-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> terminated:</span>
<span id="annotated-cell-25-22"><a href="#annotated-cell-25-22" aria-hidden="true" tabindex="-1"></a>        episode_length <span class="op">+=</span> <span class="dv">1</span></span>
<span id="annotated-cell-25-23"><a href="#annotated-cell-25-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-25-24"><a href="#annotated-cell-25-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># behaviour: uniformly random</span></span>
<span id="annotated-cell-25-25"><a href="#annotated-cell-25-25" aria-hidden="true" tabindex="-1"></a>        action <span class="op">=</span> rng.choice(env.action_space)</span>
<span id="annotated-cell-25-26"><a href="#annotated-cell-25-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-25-27"><a href="#annotated-cell-25-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if non-compliant, return (0, 0)</span></span>
<span id="annotated-cell-25-28"><a href="#annotated-cell-25-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> action <span class="op">!=</span> œÄ[state]:</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-25" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-25-29" class="code-annotation-target"><a href="#annotated-cell-25-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="annotated-cell-25-30"><a href="#annotated-cell-25-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-25-31"><a href="#annotated-cell-25-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># otherwise, continue as usual</span></span>
<span id="annotated-cell-25-32"><a href="#annotated-cell-25-32" aria-hidden="true" tabindex="-1"></a>        state, reward, terminated <span class="op">=</span> env.step(action)</span>
<span id="annotated-cell-25-33"><a href="#annotated-cell-25-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-25-34"><a href="#annotated-cell-25-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compliant for the entire episode:</span></span>
<span id="annotated-cell-25-35"><a href="#annotated-cell-25-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">2</span><span class="op">**</span>episode_length, reward</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-25" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-25" data-code-lines="29" data-code-annotation="1">It‚Äôs ok to return <span class="math inline">\((w,G) = (0,0)\)</span> as soon as <span class="math inline">\(b\)</span> is non-compliant. We don‚Äôt have to know the real <span class="math inline">\(G\)</span>. It only appears in products <span class="math inline">\(w \cdot G\)</span> so its value doesn‚Äôt matter if <span class="math inline">\(w = 0\)</span>.</span>
</dd>
</dl>
</div>
</div>
<p>Just to get a feel for it we can see the returns for 10 episodes</p>
<div id="56f02000" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> random.Random(<span class="dv">0</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>start_state <span class="op">=</span> State(<span class="dv">13</span>, <span class="va">True</span>, <span class="dv">2</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    w, r <span class="op">=</span> bj_importance_weight_compliance(env, œÄ_at_least_20, start_state, rng)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"episode </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">:2d}</span><span class="ss"> ‚Äì Weight </span><span class="sc">{</span>w<span class="sc">}</span><span class="ss">, return </span><span class="sc">{</span>r<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>episode  1 ‚Äì Weight 0, return 0
episode  2 ‚Äì Weight 0, return 0
episode  3 ‚Äì Weight 0, return 0
episode  4 ‚Äì Weight 0, return 0
episode  5 ‚Äì Weight 0, return 0
episode  6 ‚Äì Weight 8, return -1
episode  7 ‚Äì Weight 0, return 0
episode  8 ‚Äì Weight 8, return -1
episode  9 ‚Äì Weight 0, return 0
episode 10 ‚Äì Weight 0, return 0</code></pre>
</div>
</div>
<p>So most of the time the weight is 0 and if not it can get quite big. This shows why ordinary importance sampling for off-policy prediction can have such high variance.</p>
<p>Now let‚Äôs plot the performance of ordinary and weighted importance sampling.</p>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mse_vs_m(</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    env, policy, start_state, max_m: <span class="bu">int</span>, iterations_per_m: <span class="bu">int</span>, true_value: <span class="bu">float</span>, rng</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Estimate MSE of ordinary and weighted importance sampling</span></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="co">    as a function of the number of episodes m.</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> compute_estimators_from_array(</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>        ep_arr: np.ndarray,</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> <span class="bu">tuple</span>[np.float64, np.float64]:</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a><span class="co">        Given an array of shape (m, 2) where:</span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a><span class="co">            col 0 = importance weights (w)</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a><span class="co">            col 1 = returns (G)</span></span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a><span class="co">        compute:</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a><span class="co">            ordinary IS = mean(w * G)</span></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a><span class="co">            weighted IS = sum(w * G) / sum(w)</span></span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>        w <span class="op">=</span> ep_arr[:, <span class="dv">0</span>]</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>        g <span class="op">=</span> ep_arr[:, <span class="dv">1</span>]</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>        ordinary_IS <span class="op">=</span> np.mean(w <span class="op">*</span> g)</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>        denom <span class="op">=</span> w.<span class="bu">sum</span>()</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>        weighted_IS <span class="op">=</span> (w <span class="op">*</span> g).<span class="bu">sum</span>() <span class="op">/</span> denom <span class="cf">if</span> denom <span class="op">!=</span> <span class="fl">0.0</span> <span class="cf">else</span> np.nan</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ordinary_IS, weighted_IS</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Prepare arrays to record MSEs for different m values ---</span></span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>    m_values <span class="op">=</span> np.arange(<span class="dv">1</span>, max_m <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>    ordinary_mses <span class="op">=</span> np.empty_like(m_values, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>    weighted_mses <span class="op">=</span> np.empty_like(m_values, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- For each m (sample size), estimate MSE over many independent runs ---</span></span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx, m <span class="kw">in</span> <span class="bu">enumerate</span>(m_values):</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>        ord_estimates <span class="op">=</span> np.empty(iterations_per_m, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>        wgt_estimates <span class="op">=</span> np.empty(iterations_per_m, dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> it <span class="kw">in</span> <span class="bu">range</span>(iterations_per_m):</span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>            <span class="co"># --- Collect m independent (weight, return) samples ---</span></span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a>            episodes <span class="op">=</span> [</span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a>                bj_importance_weight_compliance(env, policy, start_state, rng)</span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(m)</span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a>            ep_arr <span class="op">=</span> np.array(episodes, dtype<span class="op">=</span><span class="bu">float</span>)  <span class="co"># shape (m, 2)</span></span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a>            ord_estimates[it], wgt_estimates[it] <span class="op">=</span> compute_estimators_from_array(ep_arr)</span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- Compute mean squared error relative to the known true value ---</span></span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true" tabindex="-1"></a>        ordinary_mses[idx] <span class="op">=</span> np.nanmean((ord_estimates <span class="op">-</span> true_value) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true" tabindex="-1"></a>        weighted_mses[idx] <span class="op">=</span> np.nanmean((wgt_estimates <span class="op">-</span> true_value) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> m_values, ordinary_mses, weighted_mses</span>
<span id="cb28-57"><a href="#cb28-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-58"><a href="#cb28-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-59"><a href="#cb28-59" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_ordinary_vs_weighted_IS(max_episodes, iterations_per_episode, rng):</span>
<span id="cb28-60"><a href="#cb28-60" aria-hidden="true" tabindex="-1"></a>    bj_env <span class="op">=</span> BlackJack()</span>
<span id="cb28-61"><a href="#cb28-61" aria-hidden="true" tabindex="-1"></a>    start_state <span class="op">=</span> State(<span class="dv">13</span>, <span class="va">True</span>, <span class="dv">2</span>)</span>
<span id="cb28-62"><a href="#cb28-62" aria-hidden="true" tabindex="-1"></a>    true_value <span class="op">=</span> <span class="op">-</span><span class="fl">0.27726</span>  <span class="co"># precomputed</span></span>
<span id="cb28-63"><a href="#cb28-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-64"><a href="#cb28-64" aria-hidden="true" tabindex="-1"></a>    m_vals, o_mses, w_mses <span class="op">=</span> mse_vs_m(</span>
<span id="cb28-65"><a href="#cb28-65" aria-hidden="true" tabindex="-1"></a>        bj_env,</span>
<span id="cb28-66"><a href="#cb28-66" aria-hidden="true" tabindex="-1"></a>        œÄ_at_least_20,</span>
<span id="cb28-67"><a href="#cb28-67" aria-hidden="true" tabindex="-1"></a>        start_state,</span>
<span id="cb28-68"><a href="#cb28-68" aria-hidden="true" tabindex="-1"></a>        max_episodes,</span>
<span id="cb28-69"><a href="#cb28-69" aria-hidden="true" tabindex="-1"></a>        iterations_per_episode,</span>
<span id="cb28-70"><a href="#cb28-70" aria-hidden="true" tabindex="-1"></a>        true_value,</span>
<span id="cb28-71"><a href="#cb28-71" aria-hidden="true" tabindex="-1"></a>        rng,</span>
<span id="cb28-72"><a href="#cb28-72" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb28-73"><a href="#cb28-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-74"><a href="#cb28-74" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Plot ---</span></span>
<span id="cb28-75"><a href="#cb28-75" aria-hidden="true" tabindex="-1"></a>    sns.lineplot(x<span class="op">=</span>m_vals, y<span class="op">=</span>o_mses, label<span class="op">=</span><span class="st">"Ordinary IS MSE"</span>, alpha<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb28-76"><a href="#cb28-76" aria-hidden="true" tabindex="-1"></a>    sns.lineplot(x<span class="op">=</span>m_vals, y<span class="op">=</span>w_mses, label<span class="op">=</span><span class="st">"Weighted IS MSE"</span>, alpha<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb28-77"><a href="#cb28-77" aria-hidden="true" tabindex="-1"></a>    plt.xscale(<span class="st">"log"</span>)</span>
<span id="cb28-78"><a href="#cb28-78" aria-hidden="true" tabindex="-1"></a>    plt.yscale(<span class="st">"log"</span>)</span>
<span id="cb28-79"><a href="#cb28-79" aria-hidden="true" tabindex="-1"></a>    plt.ylim(top<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb28-80"><a href="#cb28-80" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">"Saple size (episodes)"</span>)</span>
<span id="cb28-81"><a href="#cb28-81" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="ss">f"Mean squarred error (over </span><span class="sc">{</span>iterations_per_episode<span class="sc">}</span><span class="ss"> runs)"</span>)</span>
<span id="cb28-82"><a href="#cb28-82" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">"Ordinary vs Weighted Importance Sampling</span><span class="ch">\n</span><span class="st">on single Blackjack state"</span>)</span>
<span id="cb28-83"><a href="#cb28-83" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb28-84"><a href="#cb28-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-85"><a href="#cb28-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-86"><a href="#cb28-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Example seed that gives nice illustrative curves # 21, 23, 38, 9112</span></span>
<span id="cb28-87"><a href="#cb28-87" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> random.Random(<span class="dv">0</span>)</span>
<span id="cb28-88"><a href="#cb28-88" aria-hidden="true" tabindex="-1"></a>max_episodes <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb28-89"><a href="#cb28-89" aria-hidden="true" tabindex="-1"></a>iterations_per_episode <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb28-90"><a href="#cb28-90" aria-hidden="true" tabindex="-1"></a><span class="co"># max_episodes = 1</span></span>
<span id="cb28-91"><a href="#cb28-91" aria-hidden="true" tabindex="-1"></a><span class="co"># iterations_per_episode = 1</span></span>
<span id="cb28-92"><a href="#cb28-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-93"><a href="#cb28-93" aria-hidden="true" tabindex="-1"></a>plot_ordinary_vs_weighted_IS(max_episodes, iterations_per_episode, rng)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-5.3-off-policy-evaluation-black-jack" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-5.3-off-policy-evaluation-black-jack-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="3775f9a4" class="cell" data-execution_count="21">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-21-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;5.4: This is like figure 5.3 from @sutton2018. Weighted importance sapling produces lower error estimates for small sample sizes. Both curves are based on the same data."><img src="05-monte-carlo-methods_files/figure-html/cell-21-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-5.3-off-policy-evaluation-black-jack-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.4: This is like figure 5.3 from <span class="citation" data-cites="sutton2018">Sutton and Barto (<a href="#ref-sutton2018" role="doc-biblioref">2018</a>)</span>. Weighted importance sapling produces lower error estimates for small sample sizes. Both curves are based on the same data.
</figcaption>
</figure>
</div>
<p>We can see in <a href="#fig-5.3-off-policy-evaluation-black-jack" class="quarto-xref">Figure&nbsp;<span>5.4</span></a> that the variance of ordinary importance sampling is higher (it produces higher spikes). For samples of size around 100 they seem to produce comparatively similar results.</p>
</div>
<div id="exm-5.5-infinite-variance" class="theorem example">
<p><span class="theorem-title"><strong>Example 5.5</strong></span> <strong>Infinite Variance</strong> <span class="citation" data-cites="sutton2018">(<a href="#ref-sutton2018" role="doc-biblioref">Sutton and Barto 2018</a>, Example 5.5)</span>.</p>
<p>I never thought about what infinite variance means in terms of statistics until this example.</p>
<p>Consider the tiny MDP in <a href="#fig-5.4-infinite-variance-mdp" class="quarto-xref">Figure&nbsp;<span>5.5 (a)</span></a>.</p>
<p>The optimal policy is <span class="math inline">\(\pi(s) = \mathrm{left}\)</span> and <span class="math inline">\(v_\pi(s) = +1\)</span>. Let‚Äôs see what importance sampling does with uniform random behaviour policy <span class="math inline">\(b\)</span>.</p>
<p>Weighted importance sampling does a pretty good job here. As soon as it‚Äôs defined, i.e., there is one compliant episode in the samples, it estimates exactly <span class="math inline">\(+1\)</span>.</p>
<p>Ordinary importance sampling, does a much worse job.</p>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gc</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Sampling function ---</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>_rng <span class="op">=</span> np.random.default_rng()</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co"># This simulates one run on the MDP given above (but much faster)</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_powers_of_two(size, rng<span class="op">=</span>_rng):</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    nonzero_mask <span class="op">=</span> rng.random(size) <span class="op">&gt;</span> <span class="dv">10</span> <span class="op">/</span> <span class="dv">11</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> np.zeros(size, dtype<span class="op">=</span>np.int64)</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    k <span class="op">=</span> nonzero_mask.<span class="bu">sum</span>()</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> k:</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>        n <span class="op">=</span> rng.geometric(<span class="fl">0.55</span>, size<span class="op">=</span>k).astype(np.int64)</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>        samples[nonzero_mask] <span class="op">=</span> <span class="dv">1</span> <span class="op">&lt;&lt;</span> n</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> samples</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Parameters ---</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a><span class="co"># N = 100_000_000</span></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">10_000_000</span></span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>num_runs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Generate and plot ---</span></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>plot_points <span class="op">=</span> <span class="dv">2000</span></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_runs):</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> sample_powers_of_two(N)</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>    running_avg <span class="op">=</span> np.cumsum(samples) <span class="op">/</span> np.arange(<span class="dv">1</span>, N <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>    raw <span class="op">=</span> np.logspace(<span class="dv">0</span>, np.log10(N), num<span class="op">=</span>plot_points)</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># indices as 1-based positions, then convert to zero-based for indexing</span></span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>    idxs <span class="op">=</span> np.unique(np.minimum(N, np.maximum(<span class="dv">1</span>, np.<span class="bu">round</span>(raw).astype(np.int64)))) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a>    xs <span class="op">=</span> idxs <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a>    ys <span class="op">=</span> running_avg[idxs]</span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a>    plt.plot(xs, ys, lw<span class="op">=</span><span class="fl">1.0</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a>    <span class="kw">del</span> running_avg</span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">del</span> samples</span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a>    gc.collect()</span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a>plt.title(</span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a>    <span class="vs">rf"MC estimate of </span><span class="dv">$</span><span class="vs">v_</span><span class="er">\</span><span class="vs">pi</span><span class="kw">(</span><span class="vs">s</span><span class="kw">)</span><span class="dv">$</span><span class="vs"> with ordinary importance sampling </span><span class="kw">(</span><span class="sc">{</span>num_runs<span class="sc">}</span><span class="vs"> runs</span><span class="kw">)</span><span class="vs">"</span></span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Sample size (Episodes)"</span>)</span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">"log"</span>)</span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"V(s)"</span>)</span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a>plt.ylim(top<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-5.4-infinite-variance" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-5.4-infinite-variance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="fig-5.4-infinite-variance-mdp" class="quarto-float quarto-figure quarto-figure-center anchored" width="10%">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-5.4-infinite-variance-mdp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="text-center">
<a href="b0d0db07d13dc282001a3a80a91b8e3f704970ab.svg" class="lightbox" data-gallery="fig-5.4-infinite-variance" title="Figure&nbsp;5.5&nbsp;(a): A MDP with only one non-terminal state s and two actions \mathrm{left} and \mathrm{right}. The action \mathrm{right} deterministically terminates the MDP with 0 reward. The action \mathrm{left} terminates with probability 0.1 with a reward of +1, in the other case it loops back to s with reward 0."><img src="05-monte-carlo-methods_files/mediabag/b0d0db07d13dc282001a3a80a91b8e3f704970ab.svg" class="img-fluid figure-img" data-ref-parent="fig-5.4-infinite-variance"></a>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-5.4-infinite-variance-mdp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) A MDP with only one non-terminal state <span class="math inline">\(s\)</span> and two actions <span class="math inline">\(\mathrm{left}\)</span> and <span class="math inline">\(\mathrm{right}\)</span>. The action <span class="math inline">\(\mathrm{right}\)</span> deterministically terminates the MDP with <span class="math inline">\(0\)</span> reward. The action <span class="math inline">\(\mathrm{left}\)</span> terminates with probability <span class="math inline">\(0.1\)</span> with a reward of <span class="math inline">\(+1\)</span>, in the other case it loops back to <span class="math inline">\(s\)</span> with reward <span class="math inline">\(0\)</span>.
</figcaption>
</figure>
</div>
<div id="fig-5.4-infinite-variance-Ordinary-IS" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-5.4-infinite-variance-Ordinary-IS-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="31463548" class="cell" data-execution_count="22">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-22-output-1.png" class="lightbox" data-gallery="fig-5.4-infinite-variance" title="Figure&nbsp;5.5&nbsp;(b): MC estimates for v_\pi(s) using ordinary importance sampling for the MDP shown above. The target policy \pi is the optimal policy and the behaviour policy is the uniform random policy."><img src="05-monte-carlo-methods_files/figure-html/cell-22-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-5.4-infinite-variance"></a></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-5.4-infinite-variance-Ordinary-IS-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) MC estimates for <span class="math inline">\(v_\pi(s)\)</span> using ordinary importance sampling for the MDP shown above. The target policy <span class="math inline">\(\pi\)</span> is the optimal policy and the behaviour policy is the uniform random policy.
</figcaption>
</figure>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-5.4-infinite-variance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.5: <span class="citation" data-cites="sutton2018">(<a href="#ref-sutton2018" role="doc-biblioref">Sutton and Barto 2018, fig. 5.4</a>)</span>. Ordinary importance sampling produces surprisingly unstable estimates on the one-state MDP shown above. The correct estimate here is 1 (<span class="math inline">\(\gamma = 1\)</span>), and, even though this is the expected value of a sample return (after importance sampling), the variance of the samples is infinite. These results are for off-policy first-visit MC.
</figcaption>
</figure>
</div>
<p>The problem for ordinary importance sampling is that the importance-weights have infinite variance. For the variance it‚Äôs a battle between very fast growing importance-weights and very fast falling probabilities, which in this case is won by the importance-weights. We look at this in a bit more detail.</p>
<p>A bit of calculating shows that the result of an episode can be described by two independent random variables:</p>
<ul>
<li><span class="math inline">\(C\)</span>: weather the episode is compliant <span class="math display">\[
\mathrm{Pr}(C = F) = 11/10, \quad \mathrm{Pr}(C = T) = 1/11
\]</span></li>
<li><span class="math inline">\(L\)</span>: the length of the episode <span class="math display">\[
\mathrm{Pr}(L = \ell) = 0.55 \cdot 0.45^{\ell - 1}.
\]</span></li>
</ul>
<p>So for one episode with reward <span class="math inline">\(G\)</span> and importance-weight <span class="math inline">\(w\)</span>: <span class="math display">\[
\begin{split}
\mathbb{E}[(wG)^2] &amp;= \mathbb{E}[(2^L \cdot [C = T])^2] \\
&amp;= \mathbb{E}[C=T] \cdot \mathbb{E}[4^L] \\
&amp;= \frac{1}{11} \sum_{\ell = 1}^\infty 4^\ell \cdot 0.55 \cdot 0.45^{\ell-1} \\
&amp;= \frac{2.2}{11} \sum_{\ell = 1}^\infty 1.8^{\ell-1} \\
&amp;= \infty
\end{split}
\]</span></p>
<p>Thus <span class="math inline">\(\mathrm{var}(wG) = \infty\)</span> and no amount of averaging can make this finite for the sample mean used by ordinary importance sampling. Thus ordinary importance sampling for this problem has infinite variance.</p>
<p>That doesn‚Äôt mean we couldn‚Äôt use it. The law of large numbers still applies and says that <span class="math inline">\(V^\mathrm{OIS}_\text{fv}(s) \to v_\pi(s)\)</span> for sample size going to infinity. But we can‚Äôt use the central limit theorem and thus the standard error does not decreases with <span class="math inline">\(1/\sqrt{n}\)</span>. However, there are other error metrics that can be used. For example the <a href="https://en.wikipedia.org/wiki/Average_absolute_deviation">mean absolute deviation</a> which is finite for <span class="math inline">\(V^\mathrm{OIS}\)</span>. But the problem is that it scales even slower then <span class="math inline">\(1/\sqrt{n}\)</span>, so, it‚Äôs eaven less usefull.</p>
</div>
<div id="exr-5.6" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.6</strong></span> What is the equation analogous to <a href="#eq-weighted-importance-sampling" class="quarto-xref">Equation&nbsp;<span>5.6</span></a> for action values <span class="math inline">\(Q(s, a)\)</span> instead of state values <span class="math inline">\(V(s)\)</span>, again given returns generated using <span class="math inline">\(b\)</span>?</p>
</div>
<div id="sol-5.6" class="proof solution">
<p><span class="proof-title"><em>Solution 5.6</em>. </span>Let‚Äôs go through all the important steps. Importance sampling trick: <span class="math display">\[
\begin{split}
q_\pi(s,a) &amp;= \mathbb{E}_{\tau \sim \pi}[G_t(\tau)| S_t = s, A_t = a] \\
&amp;= \sum_{\tau} G_t(\tau) p_\pi(\tau | S_t = s, A_t = a) \\
&amp;= \sum_{\tau} G_t(\tau) \frac{p_\pi(\tau | S_t = s, A_t = a)}{p_b(\tau | S_t = s, A_t = a)}p_b(\tau | S_t = s, A_t = a) \\
&amp;= \mathbb{E}_{\tau\sim b} [w_{t+1}(\tau)G_t(\tau) | S_t = s, A_t = a]
\end{split}
\]</span></p>
<p>The last line follows from: <span class="math display">\[
\begin{split}
\frac{p_\pi(\tau | S_t = s, A_t = a)}{p_b(\tau | S_t = s, A_t = a)}
&amp;= \frac{\pi(A_{t+1}|S_{t+1})\dots \pi(A_{T-1}|S_{T-1})}{b(A_{t+1}|S_{t+1})\dots b(A_{T-1}|S_{T-1})} \\
&amp;= w_{t+1}(\tau)
\end{split}
\]</span></p>
<p>So we get for ordinary importance sampling <span class="math display">\[
Q^{\mathrm{OIS}}(s,a) = \frac{\sum_{(i,t) \in \mathcal{T}(s,a)} w_{t+1}(\tau_i) G_t(\tau_i)}{|\mathcal{T}(s,a)|}
\]</span></p>
<p>and for weighted importance sampling <span class="math display">\[
Q^{\mathrm{WIS}}(s,a) = \frac{\sum_{(i,t) \in \mathcal{T}(s,a)} w_{t+1}(\tau_i) G_t(\tau_i)}{\sum_{(i,t) \in \mathcal{T}(s,a)} w_{t+1}(\tau_i)}
\]</span></p>
</div>
<div id="exr-5.7" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.7</strong></span> In learning curves such as those shown in <a href="#fig-5.3-off-policy-evaluation-black-jack" class="quarto-xref">Figure&nbsp;<span>5.4</span></a> error generally decreases with training, as indeed happened for the ordinary importance-sampling method. But for the weighted importance-sampling method error first increased and then decreased. Why do you think this happened?</p>
</div>
<div id="sol-5.7" class="proof solution">
<p><span class="proof-title"><em>Solution 5.7</em>. </span>The increasing/decreasing behaviour is not that visible in my plot. It looks it is visible but it‚Äôs rather an effect of the variance. When we increase the number of runs we can see that the curve curve goes down but slower than ordinary importance sampling at first:</p>
<div id="bd733148" class="cell" data-execution_count="23">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example seed that gives nice illustrative curves # 21, 23, 38, 9112</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> random.Random(<span class="dv">0</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>max_episodes <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>iterations_per_episode <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co"># max_m = 1</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="co"># iterations_per_m = 1</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>plot_ordinary_vs_weighted_IS(max_episodes, iterations_per_episode, rng)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-23-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="05-monte-carlo-methods_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Nonetheless this is most likely duo to the bias of weighted importance sampling. Note that for an estimator we have <span class="math display">\[
\text{MSE} = \text{Var} + \text{Bias}^2
\]</span></p>
<p>The Bias term goes away pretty quickly but for small samples it still skews the estimator away from the true value.</p>
</div>
<div id="exr-5.8" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.8</strong></span> The results with <a href="#exm-5.5-infinite-variance" class="quarto-xref">Example&nbsp;<span>5.5</span></a> and shown in <a href="#fig-5.4-infinite-variance" class="quarto-xref">Figure&nbsp;<span>5.5</span></a> used a first-visit MC method. Suppose that instead an every-visit MC method was used on the same problem. Would the variance of the estimator still be infinite? Why or why not?</p>
</div>
<div id="sol-5.8" class="proof solution">
<p><span class="proof-title"><em>Solution 5.8</em>. </span>To show that the variance of the every-visit ordinary importance sapmling estimator <span class="math inline">\(V^\mathrm{OIS}_\text{ev}\)</span> is infinite we will show that <span class="math inline">\(\mathbb{E}[(V^\mathrm{OIS}_\text{ev})^2]\)</span>.</p>
<p>As said in <a href="#exm-5.5-infinite-variance" class="quarto-xref">Example&nbsp;<span>5.5</span></a> we can describe a single episode as a random vector <span class="math inline">\((C,L)\)</span> with <span class="math inline">\(C\)</span> flaging if the episode is compliant and <span class="math inline">\(L\)</span> the length of the episode. The sum <span class="math inline">\(\sum w_tG_t\)</span> for this episode is then <span class="math display">\[
\sum w_tG_t = [C = T] \sum 2^t = [C = T] 2^{L+1} - 2
\]</span></p>
<p>Now we can describe the general case with <span class="math inline">\(m\)</span> episodes which can be modeled by <span class="math inline">\(m\)</span> i.i.d. random vectors <span class="math inline">\((C_1,L_1),\dots,(C_m,L_m)\)</span> and <span class="math display">\[
V^\mathrm{OIS}_\text{ev} = \frac{\sum_{i=1}^m [C = T] (2^{L_i+1}-2)}{\sum_{i=1}^m L_i}
\]</span></p>
<p>Now we can provide an estimate <span class="math display">\[
\begin{split}
\mathbb{E}[(V^\mathrm{OIS}_\text{ev})^2] &amp;\geq \sum_{\ell = 1}^\infty \left(\frac{(2^{\ell+1}-2) + \sum_{i=2}^m (2^{1+1}-2)}{\ell + \sum_{i=1}^m 1}\right)^2 \\
&amp;\quad\cdot \mathrm{Pr}(L_1 = \ell, L_2,\dots,L_m = 1) \\
&amp;\quad\cdot \mathrm{Pr}(C_1, \dots, C_m = 1) \\
&amp;= \sum_{\ell = 1}^\infty \left(\frac{2^{\ell+1}+2(m-2)}{\ell+m-1}\right)^2 \cdot  0.55^m \cdot 0.45^{\ell-1} \cdot (1/11)^m \\
&amp;\approx \sum_{\ell = 1}^\infty 4^\ell 0.45^\ell\\
&amp;= \infty
\end{split}
\]</span></p>
<p>So since the second moment is infinite the variance is too.</p>
</div>
</section>
</section>
</section>
<section id="incremental-implementation" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="incremental-implementation"><span class="header-section-number">5.6</span> Incremental Implementation</h2>
<p>We have returns <span class="math inline">\(G_1,\dots,G_{n-1}\)</span> and random weights <span class="math inline">\(W_1,\dots,W_{n-1}\)</span>. The weighted average is <span class="math display">\[
V_n = \frac{\sum_{k=1}^{n-1}W_kG_k}{\sum_{k=1}^{n-1}W_k}
\]</span></p>
<div id="exr-5.9" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.9</strong></span> Modify the algorithm for first-visit MC policy evaluation (<a href="06-temporal-difference-learning.html#lst-mc-prediction-first-visit" class="quarto-xref">Listing&nbsp;<span>6.1</span></a>) to use the incremental implementation for sample averages described in Section 2.4.</p>
</div>
<div id="sol-5.9" class="proof solution">
<p><span class="proof-title"><em>Solution 5.9</em>. </span></p>
<div class="listing-block">
<div class="line-block"><strong>Input</strong>: <span class="math inline">\(\pi\)</span>, the policy to be evaluated<br>
<strong>Initialisation</strong>: <span class="math inline">\(V(s) \gets 0\)</span>, for all <span class="math inline">\(s \in \mathcal{S}\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(N(s) \gets 0\)</span>, for all <span class="math inline">\(s \in \mathcal{S}\)</span><br>
<br>
Loop forever:<br>
&nbsp;&nbsp;&nbsp;&nbsp;Generate an episode following <span class="math inline">\(\pi\)</span>: <span class="math inline">\(S_0,A_0, R_1, S_1, A_1, \dots, R_T, S_T\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(G \gets 0\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;Loop for each step of episode, <span class="math inline">\(t = T-1, T-2, \dots, 0\)</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(G \gets \gamma G + R_{t+1}\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;If <span class="math inline">\(S_t\)</span> is not in <span class="math inline">\(\{S_0,S_1, \dots, S_{t-1}\}\)</span>:<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(N(S_t) \gets N(S_t) + 1\)</span><br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(V(S_t) \gets V(S_t) + \frac{1}{N(S_t)}[G - V(S_t)]\)</span></div>
</div>
</div>
<div id="exr-5.10" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.10</strong></span> Derive the weighted-average update rule (5.8) from (5.7). Follow the pattern of the derivation of the unweighted rule (2.3).</p>
</div>
<div id="sol-5.10" class="proof solution">
<p><span class="proof-title"><em>Solution 5.10</em>. </span>TBD</p>
</div>
</section>
<section id="off-policy-monte-carlo-control" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="off-policy-monte-carlo-control"><span class="header-section-number">5.7</span> Off-policy Monte Carlo Control</h2>
<div id="exr-5.11" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.11</strong></span> In the boxed algorithm for off-policy MC control, you may have been expecting the <span class="math inline">\(W\)</span> update to have involved the importance-sampling ratio <span class="math inline">\(\frac{\pi(A_t|S_t)}{b(A_t|S_t)}\)</span>, but instead it involves <span class="math inline">\(\frac{1}{b(A_t|S_t)}\)</span>. Why is this nevertheless correct?</p>
</div>
<div id="sol-5.11" class="proof solution">
<p><span class="proof-title"><em>Solution 5.11</em>. </span>The whole thing about proceeding to the next episode and updating <span class="math inline">\(W\)</span> is just complinace. If the behavioral policy does something the target policy would not do, the weight is <span class="math inline">\(0\)</span>. In the other case the importance sampling ratio is just <span class="math display">\[
\frac{\pi(A_t|S_t)}{b(A_t|S_t)} = \frac{1}{b(A_t|S_t)}
\]</span></p>
</div>
<div id="exr-5.12" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercise 5.12</strong></span> Consider driving a race car around a turn like those shown in Figure 5.5. You want to go as fast as possible, but not so fast as to run off the track. In our simplified racetrack, the car is at one of a discrete set of grid positions, the cells in the diagram. The velocity is also discrete, a number of grid cells moved horizontally and vertically per time step. The actions are increments to the velocity components. Each may be changed by <span class="math inline">\(+1\)</span>, <span class="math inline">\(-1\)</span>, or <span class="math inline">\(0\)</span> in each step, for a total of nine (<span class="math inline">\(3 \times 3\)</span>) actions. Both velocity components are restricted to be nonnegative and less than <span class="math inline">\(5\)</span>, and they cannot both be zero except at the starting line. Each episode begins in one of the randomly selected start states with both velocity components zero and ends when the car crosses the finish line. The rewards are 1 for each step until the car crosses the finish line. If the car hits the track boundary, it is moved back to a random position on the starting line, both velocity components are reduced to zero, and the episode continues. Before updating the car‚Äôs location at each time step, check to see if the projected path of the car intersects the track boundary. If it intersects the finish line, the episode ends; if it intersects anywhere else, the car is considered to have hit the track boundary and is sent back to the starting line. To make the task more challenging, with probability <span class="math inline">\(0.1\)</span> at each time step the velocity increments are both zero, independently of the intended increments. Apply a Monte Carlo control method to this task to compute the optimal policy from each starting state. Exhibit several trajectories following the optimal policy (but turn the noise off for these trajectories).</p>
</div>
<div id="sol-5.12" class="proof solution">
<p><span class="proof-title"><em>Solution 5.12</em>. </span>This is a substantial exercise. Setting up the environment, the training code, debugging everyting. That‚Äôs quite a lot of work. Also training on the full-size tracks is too much to do inside these notes. So I use a smaller track for exposition (<a href="#fig-track-choice" class="quarto-xref">Figure&nbsp;<span>5.6</span></a>) and for the bigger problems I use pretrained models.</p>
<p>On all problem I use on-policy <span class="math inline">\(\varepsilon\)</span>-soft first-visit sample-average Monte-Carlo control for training. That‚Äôs quite a mouthfull but I will discuss each of these modifiers in this solution. At the very end I will also say some thoughts about Monte-Carlo exploring-starts and off-policy Monte-Carlo.</p>
<section id="the-track-environment" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-track-environment">The track environment</h4>
<p>I externalised the racetrack environment into <code>scripts.environment.race_track</code>. Its only required argument is the layout represented as an ASCII string. There are some other knobs, among them the size of the maximal velocity components <code>max_velocity</code> or if the velocity components can be negative <code>only_positive_velocity</code><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. How I read the exercise, they want <code>only_positive_velocity=True</code> but I think that‚Äôs a bit strange, especially since then some parts of the provided exmaple tracks would be unreachable. So I will use <code>only_posititve_velocity=False</code> in all of the environments. Also <code>prob_steering_failure=0.1</code> by default, as required in the exercise.</p>
<p>In the next code I define the small example <code>env_tight</code>. This environment only allows has <code>max_velocity=2</code>, this makes optimal episodes taking the left route shorter than taking the right route.</p>
<div id="949b004f" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scripts.environment.race_track <span class="im">as</span> rt</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>track_tight <span class="op">=</span> <span class="st">""" </span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="st">##FFF</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="st">##---</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="st">F#---</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="st">-#---</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="st">-#---</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="st">-#---</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="st">-#---</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="st">-#---</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="st">-#---</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="st">-S---</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>env_tight <span class="op">=</span> rt.RaceTrack(</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    track_tight,</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    only_positive_velocity<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    max_velocity<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The figure explains the track a bit more in detail</p>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scripts.environment.race_track <span class="im">as</span> rt</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.colors <span class="im">import</span> ListedColormap</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_episode(env, states, title<span class="op">=</span><span class="va">None</span>, radius<span class="op">=</span><span class="fl">0.3</span>, figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">8</span>)):</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Annotate every visit (timestep) but jitter repeated visits around the cell.</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co">    radius: radial offset (in cell units) for jitter ring; increase if labels collide.</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>figsize)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> env.grid._track.T</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>    cmap <span class="op">=</span> ListedColormap([<span class="st">"#444444"</span>, <span class="st">"#e68a8a"</span>, <span class="st">"#f2f2f2"</span>, <span class="st">"#8fd18f"</span>])</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>    ax.imshow(img, cmap<span class="op">=</span>cmap, origin<span class="op">=</span><span class="st">"lower"</span>, interpolation<span class="op">=</span><span class="st">"nearest"</span>)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>    ax.set_xticks(np.arange(env.grid.width))</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>    ax.set_yticks(np.arange(env.grid.height))</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>    ax.set_xlim(<span class="op">-</span><span class="fl">0.5</span>, env.grid.width <span class="op">-</span> <span class="fl">0.5</span>)</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>    ax.set_ylim(<span class="op">-</span><span class="fl">0.5</span>, env.grid.height <span class="op">-</span> <span class="fl">0.5</span>)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>    ax.set_aspect(<span class="st">"equal"</span>)</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Rotate x-tick labels</span></span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>    plt.setp(ax.get_xticklabels(), rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">"right"</span>)</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># grid lines</span></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(env.grid.width):</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> y <span class="kw">in</span> <span class="bu">range</span>(env.grid.height):</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>            rect <span class="op">=</span> plt.Rectangle(</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>                (x <span class="op">-</span> <span class="fl">0.5</span>, y <span class="op">-</span> <span class="fl">0.5</span>),</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a>                <span class="dv">1</span>,</span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>                <span class="dv">1</span>,</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>                fill<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>                edgecolor<span class="op">=</span><span class="st">"#444444"</span>,</span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a>                linewidth<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>            ax.add_patch(rect)</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(states) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a>        positions <span class="op">=</span> [s.position <span class="cf">for</span> s <span class="kw">in</span> states]</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a>        xs <span class="op">=</span> [p[<span class="dv">0</span>] <span class="cf">for</span> p <span class="kw">in</span> positions]</span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a>        ys <span class="op">=</span> [p[<span class="dv">1</span>] <span class="cf">for</span> p <span class="kw">in</span> positions]</span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a>        ax.plot(xs, ys, marker<span class="op">=</span><span class="st">"o"</span>)</span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Build map from position -&gt; list of visit indices</span></span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a>        visits <span class="op">=</span> {}</span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t, pos <span class="kw">in</span> <span class="bu">enumerate</span>(positions):</span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a>            visits.setdefault(pos, []).append(t)</span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Annotate each visit with radial offsets to avoid overlap</span></span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> pos, idx_list <span class="kw">in</span> visits.items():</span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a>            x0, y0 <span class="op">=</span> pos</span>
<span id="cb32-56"><a href="#cb32-56" aria-hidden="true" tabindex="-1"></a>            n <span class="op">=</span> <span class="bu">len</span>(idx_list)</span>
<span id="cb32-57"><a href="#cb32-57" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> k, t <span class="kw">in</span> <span class="bu">enumerate</span>(idx_list):</span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> n <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a>                    dx, dy <span class="op">=</span> (<span class="fl">0.08</span>, <span class="fl">0.18</span>)</span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a>                    angle <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> math.pi <span class="op">*</span> k <span class="op">/</span> n</span>
<span id="cb32-62"><a href="#cb32-62" aria-hidden="true" tabindex="-1"></a>                    dx <span class="op">=</span> math.cos(angle) <span class="op">*</span> radius</span>
<span id="cb32-63"><a href="#cb32-63" aria-hidden="true" tabindex="-1"></a>                    dy <span class="op">=</span> math.sin(angle) <span class="op">*</span> radius</span>
<span id="cb32-64"><a href="#cb32-64" aria-hidden="true" tabindex="-1"></a>                ax.text(</span>
<span id="cb32-65"><a href="#cb32-65" aria-hidden="true" tabindex="-1"></a>                    x0 <span class="op">+</span> dx,</span>
<span id="cb32-66"><a href="#cb32-66" aria-hidden="true" tabindex="-1"></a>                    y0 <span class="op">+</span> dy,</span>
<span id="cb32-67"><a href="#cb32-67" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">str</span>(t),</span>
<span id="cb32-68"><a href="#cb32-68" aria-hidden="true" tabindex="-1"></a>                    fontsize<span class="op">=</span><span class="dv">9</span>,</span>
<span id="cb32-69"><a href="#cb32-69" aria-hidden="true" tabindex="-1"></a>                    va<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb32-70"><a href="#cb32-70" aria-hidden="true" tabindex="-1"></a>                    ha<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb32-71"><a href="#cb32-71" aria-hidden="true" tabindex="-1"></a>                    bbox<span class="op">=</span><span class="bu">dict</span>(boxstyle<span class="op">=</span><span class="st">"round,pad=0.1"</span>, alpha<span class="op">=</span><span class="fl">0.9</span>),</span>
<span id="cb32-72"><a href="#cb32-72" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb32-73"><a href="#cb32-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-74"><a href="#cb32-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> title:</span>
<span id="cb32-75"><a href="#cb32-75" aria-hidden="true" tabindex="-1"></a>        ax.set_title(title)</span>
<span id="cb32-76"><a href="#cb32-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-77"><a href="#cb32-77" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> fig, ax</span>
<span id="cb32-78"><a href="#cb32-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-79"><a href="#cb32-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-80"><a href="#cb32-80" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plot_episode(</span>
<span id="cb32-81"><a href="#cb32-81" aria-hidden="true" tabindex="-1"></a>    env_tight,</span>
<span id="cb32-82"><a href="#cb32-82" aria-hidden="true" tabindex="-1"></a>    [],</span>
<span id="cb32-83"><a href="#cb32-83" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-84"><a href="#cb32-84" aria-hidden="true" tabindex="-1"></a>fig.set_size_inches(<span class="fl">2.5</span>, <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-track-choice" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-track-choice-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="4e2b0d8d" class="cell" data-execution_count="25">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-25-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Figure&nbsp;5.6: A plot of the layout of env_tight. In the plots the starting cells are red, green squares the finish cells, the squares are the normal track pieces, and the dark squares the walls. The best route is going left and has a length of 5. Going the right path requires one more step."><img src="05-monte-carlo-methods_files/figure-html/cell-25-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-track-choice-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.6: A plot of the layout of <code>env_tight</code>. In the plots the starting cells are red, green squares the finish cells, the squares are the normal track pieces, and the dark squares the walls. The best route is going left and has a length of 5. Going the right path requires one more step.
</figcaption>
</figure>
</div>
</section>
<section id="on-policy-first-visit-mc-control-for-Œµ-soft-policies" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="on-policy-first-visit-mc-control-for-Œµ-soft-policies">On-policy first-visit MC control (for Œµ-soft policies)</h3>
<p>We need to implement <a href="#lst-mc-control-on-policy-first-visit" class="quarto-xref">Listing&nbsp;<span>5.3</span></a>. The algorithm lends itself to the following implementation, where the policies are deterministic, but in the episode generation we soften these to <span class="math inline">\(\varepsilon\)</span>-soft policies, this is basically an implementation of the idea that <span class="math inline">\(\varepsilon\)</span>-soft policies can be thought of hard policies on the a changed environment that randomices the choosen action with probablity <span class="math inline">\(\varepsilon\)</span> <span class="citation" data-cites="sutton2018">(<a href="#ref-sutton2018" role="doc-biblioref">Sutton and Barto 2018, chap. 5.4</a>)</span>.</p>
<p>This is what <code>generate_episode_soft</code> does, it takes an envirnment, a deterministic policy, an <span class="math inline">\(\varepsilon\)</span> and produces an episode following <span class="math inline">\(\pi\)</span> where each step the action gets randomply choosen with probablity <span class="math inline">\(\varepsilon\)</span>. With that the implementation of <a href="#lst-mc-control-on-policy-first-visit" class="quarto-xref">Listing&nbsp;<span>5.3</span></a> in <code>on_policy_mc_control_soft</code> is actually quite similar to the code used <a href="#exm-5.3-solving-black-jack" class="quarto-xref">Example&nbsp;<span>5.3</span></a> for MC exploring starts. In a sense on-policy <span class="math inline">\(\varepsilon\)</span>-soft MC control could be thought of as Monte Carlo with exploring episodes.</p>
<div id="10303322" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_episode_soft(</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    env: rt.RaceTrack,</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    œÄ: <span class="bu">dict</span>[rt.State, rt.Action],</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    Œµ: <span class="bu">float</span>,</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    rng: random.Random,</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    start_pos<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>    max_lenght<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>    states <span class="op">=</span> []  <span class="co"># S_0, ..., S_T</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>    rewards <span class="op">=</span> []  <span class="co"># R_0, ..., R_T</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    actions <span class="op">=</span> []  <span class="co"># A_0, ..., A_{T-1}</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> start_pos:</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>        state, reward, terminated <span class="op">=</span> env.set_state(rt.State(start_pos, (<span class="dv">0</span>, <span class="dv">0</span>)))</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>        state, reward, terminated <span class="op">=</span> env.reset()</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    states.append(state)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    rewards.append(reward)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    ep_length <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="kw">not</span> terminated:</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (<span class="kw">not</span> max_lenght <span class="kw">is</span> <span class="va">None</span>) <span class="kw">and</span> ep_length <span class="op">&gt;=</span> max_lenght:</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">RuntimeError</span>(<span class="st">"episode seems to be too long"</span>)</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>        ep_length <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>        greedy_action <span class="op">=</span> œÄ[state]</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Œµ-greedy behaviour policy</span></span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> rng.random() <span class="op">&lt;</span> Œµ:</span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>            action <span class="op">=</span> rng.choice(env.action_space)</span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a>            action <span class="op">=</span> greedy_action</span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-38"><a href="#cb33-38" aria-hidden="true" tabindex="-1"></a>        actions.append(action)</span>
<span id="cb33-39"><a href="#cb33-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-40"><a href="#cb33-40" aria-hidden="true" tabindex="-1"></a>        state, reward, terminated <span class="op">=</span> env.step(action)</span>
<span id="cb33-41"><a href="#cb33-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-42"><a href="#cb33-42" aria-hidden="true" tabindex="-1"></a>        states.append(state)</span>
<span id="cb33-43"><a href="#cb33-43" aria-hidden="true" tabindex="-1"></a>        rewards.append(reward)</span>
<span id="cb33-44"><a href="#cb33-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-45"><a href="#cb33-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> states, rewards, actions</span>
<span id="cb33-46"><a href="#cb33-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-47"><a href="#cb33-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-48"><a href="#cb33-48" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> on_policy_mc_control_soft(env: rt.RaceTrack, n_episodes, Œµ, rng: random.Random):</span>
<span id="cb33-49"><a href="#cb33-49" aria-hidden="true" tabindex="-1"></a>    q <span class="op">=</span> {</span>
<span id="cb33-50"><a href="#cb33-50" aria-hidden="true" tabindex="-1"></a>        (state, action): rng.random()</span>
<span id="cb33-51"><a href="#cb33-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> state <span class="kw">in</span> env.state_space</span>
<span id="cb33-52"><a href="#cb33-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> action <span class="kw">in</span> env.action_space</span>
<span id="cb33-53"><a href="#cb33-53" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb33-54"><a href="#cb33-54" aria-hidden="true" tabindex="-1"></a>    œÄ <span class="op">=</span> {</span>
<span id="cb33-55"><a href="#cb33-55" aria-hidden="true" tabindex="-1"></a>        state: <span class="bu">max</span>(env.action_space, key<span class="op">=</span><span class="kw">lambda</span> action: q[(state, action)])</span>
<span id="cb33-56"><a href="#cb33-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> state <span class="kw">in</span> env.state_space</span>
<span id="cb33-57"><a href="#cb33-57" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb33-58"><a href="#cb33-58" aria-hidden="true" tabindex="-1"></a>    c <span class="op">=</span> {(state, action): <span class="dv">0</span> <span class="cf">for</span> state <span class="kw">in</span> env.state_space <span class="cf">for</span> action <span class="kw">in</span> env.action_space}</span>
<span id="cb33-59"><a href="#cb33-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-60"><a href="#cb33-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># record loss for diagnostic</span></span>
<span id="cb33-61"><a href="#cb33-61" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> []</span>
<span id="cb33-62"><a href="#cb33-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-63"><a href="#cb33-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_episodes):</span>
<span id="cb33-64"><a href="#cb33-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># make an episode</span></span>
<span id="cb33-65"><a href="#cb33-65" aria-hidden="true" tabindex="-1"></a>        states, rewards, actions <span class="op">=</span> generate_episode_soft(env, œÄ, Œµ, rng)</span>
<span id="cb33-66"><a href="#cb33-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-67"><a href="#cb33-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># first visit</span></span>
<span id="cb33-68"><a href="#cb33-68" aria-hidden="true" tabindex="-1"></a>        G <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb33-69"><a href="#cb33-69" aria-hidden="true" tabindex="-1"></a>        state_actions <span class="op">=</span> [(states[i], actions[i]) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(actions))]</span>
<span id="cb33-70"><a href="#cb33-70" aria-hidden="true" tabindex="-1"></a>        visit_counter <span class="op">=</span> Counter(state_actions)</span>
<span id="cb33-71"><a href="#cb33-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">reversed</span>(<span class="bu">range</span>(<span class="bu">len</span>(actions))):</span>
<span id="cb33-72"><a href="#cb33-72" aria-hidden="true" tabindex="-1"></a>            G <span class="op">+=</span> rewards[i <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb33-73"><a href="#cb33-73" aria-hidden="true" tabindex="-1"></a>            sa <span class="op">=</span> state_actions[i]</span>
<span id="cb33-74"><a href="#cb33-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-75"><a href="#cb33-75" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> visit_counter[sa] <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb33-76"><a href="#cb33-76" aria-hidden="true" tabindex="-1"></a>                visit_counter[sa] <span class="op">+=</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb33-77"><a href="#cb33-77" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb33-78"><a href="#cb33-78" aria-hidden="true" tabindex="-1"></a>                <span class="co"># update q</span></span>
<span id="cb33-79"><a href="#cb33-79" aria-hidden="true" tabindex="-1"></a>                c[sa] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb33-80"><a href="#cb33-80" aria-hidden="true" tabindex="-1"></a>                q[sa] <span class="op">+=</span> (G <span class="op">-</span> q[sa]) <span class="op">/</span> c[sa]</span>
<span id="cb33-81"><a href="#cb33-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-82"><a href="#cb33-82" aria-hidden="true" tabindex="-1"></a>                <span class="co"># update œÄ</span></span>
<span id="cb33-83"><a href="#cb33-83" aria-hidden="true" tabindex="-1"></a>                state <span class="op">=</span> sa[<span class="dv">0</span>]</span>
<span id="cb33-84"><a href="#cb33-84" aria-hidden="true" tabindex="-1"></a>                œÄ[state] <span class="op">=</span> <span class="bu">max</span>(env.action_space, key<span class="op">=</span><span class="kw">lambda</span> a: q[(state, a)])</span>
<span id="cb33-85"><a href="#cb33-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-86"><a href="#cb33-86" aria-hidden="true" tabindex="-1"></a>        loss.append(<span class="op">-</span>G)</span>
<span id="cb33-87"><a href="#cb33-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-88"><a href="#cb33-88" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> œÄ, q, loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="training-the-small-example" class="level3 unnumbered">
<h3 class="unnumbered anchored" data-anchor-id="training-the-small-example">Training the small example</h3>
<p>So let‚Äôs train an <span class="math inline">\(\varepsilon\)</span>-soft agent for <code>env_tight</code> with <span class="math inline">\(\varepsilon = 0.1\)</span> and plot the <em>loss</em> that occured during the training. The term loss is generally used in gradient descent methods and is the thing which is tried to be minimized. I thought it would be a good fit here. In our case the loss is just the length of the episode. The shorter the episode, the better.</p>
<div id="e07e4533" class="cell" data-execution_count="27">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># preparation</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> random.Random(<span class="dv">10</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>env_tight.rng <span class="op">=</span> rng</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>env_tight.prob_steering_failure <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="co"># training</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>Œµ <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>n_episodes <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>œÄ_tight, q_tight, loss_tight <span class="op">=</span> on_policy_mc_control_soft(</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>    env_tight,</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    n_episodes,</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>    Œµ,</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>    rng,</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a><span class="co"># plotting</span></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>window <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>loss_avg <span class="op">=</span> np.convolve(loss_tight, np.ones(window) <span class="op">/</span> window, mode<span class="op">=</span><span class="st">"valid"</span>)</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>plt.plot(</span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">range</span>(<span class="dv">1</span>, n_episodes <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>    loss_tight,</span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"Loss (episode length)"</span>,</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.3</span>,</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a>plt.plot(</span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">range</span>(<span class="dv">1</span>, n_episodes <span class="op">+</span> <span class="dv">1</span>)[window <span class="op">-</span> <span class="dv">1</span> :],</span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a>    loss_avg,</span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="ss">f"Average over </span><span class="sc">{</span>window<span class="sc">}</span><span class="ss"> episodes"</span>,</span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a>plt.plot(</span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">range</span>(<span class="dv">1</span>, n_episodes <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">4</span>] <span class="op">*</span> n_episodes,</span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a>    linestyle<span class="op">=</span><span class="st">"--"</span>,</span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="ss">f"Length optimal episode"</span>,</span>
<span id="cb34-37"><a href="#cb34-37" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-38"><a href="#cb34-38" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">"log"</span>)</span>
<span id="cb34-39"><a href="#cb34-39" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Loss during training on `env_tight`"</span>)</span>
<span id="cb34-40"><a href="#cb34-40" aria-hidden="true" tabindex="-1"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-27-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10"><img src="05-monte-carlo-methods_files/figure-html/cell-27-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Overall, the loss doesn‚Äôt go up, and also has some significant drops, which is good. We can also see that in this training run there is only a single episode that reaches the optimal running length of 4 and in the later episodes it regularily gets to 5. Also note that the first couple of episodes had enourmus lengts for the of over 10,000. This is the problem balancing explotaition and exploration again. If I had choosen a higher <span class="math inline">\(\varepsilon\)</span> then the first couple of episodes would be smaller but the agent had less possibilities to improve as more often it‚Äôs actions are out of its control.</p>
<p>These very long intial episodes are also a reason why it‚Äôs a bad idea to use every-visit MC for this problem. In every-visit MC these long episodes give lots of unhelpful rewards, I‚Äôm pretty sure that some episodes have more every-visits in the first 10 episodes than first-visit in the total run of the training. Also, in this problem good policies usually produce episodes that visit every state once anyways.</p>
<p>Now, let‚Äôs see what the trained policy produces without steering failures:</p>
<div id="c069bcb6" class="cell" data-execution_count="28">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>env_tight.prob_steering_failure <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>states, _, _ <span class="op">=</span> generate_episode_soft(</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    env_tight,</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    œÄ_tight,</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.0</span>,</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    rng,</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    max_lenght<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>plot_episode(env_tight, states)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-28-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="05-monte-carlo-methods_files/figure-html/cell-28-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>As seen in the loss, the policy prefers taking the right path. Mostl likely, going right is optimal for <span class="math inline">\(\varepsilon\)</span>-soft policies with <span class="math inline">\(\varepsilon=0.1\)</span>.</p>
<p>This is a demonstration thet soft policies can to avoid optimal behaviour if they require clutch control without error for failure.</p>
<section id="the-big-tracks" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-big-tracks">The big tracks</h4>
<p>Now let‚Äôs turn our attention to the original problems <span class="citation" data-cites="sutton2018">(<a href="#ref-sutton2018" role="doc-biblioref">Sutton and Barto 2018, fig. 5.5</a>)</span>. The code that we have used so far is too slow for these problems and also for the approach I have chosen learning requires hundreds of millions of episodes on these problems. So I have used a script in <code>scripts/solving_race_track/train_left_track.py</code> and <code>scripts/solving_race_track/train_right_track.py</code> to train policies for a couple of hours. Although, if you want really fast code I wouldn‚Äôt use python.</p>
<p>We start with the right track, because surprisingly it‚Äôs easier to solve. It‚Äôs an interesting observation. The right track has a bigger state space but is easier for our MC method, since the space of <em>relevant</em> states, states that actually matter for a typical run is smaller. This is because optimised episodes for the right track are actually shorter, as the finishing line has a lower y-coordinate, and thus can be reached in fewer steps. Also intiially‚Äîwhere randomness very high‚Äîthe average episode lengths are shorter.</p>
<p>This code loads the trained policy, the environment and also the loss during training.</p>
<div id="7e2affb8" class="cell" data-execution_count="29">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">"results/race_track_right.pkl"</span>, <span class="st">"rb"</span>) <span class="im">as</span> file_in:</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> pickle.load(file_in)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>n_episodes_right <span class="op">=</span> result[<span class="st">"num_episodes"</span>]</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>œÄ_right <span class="op">=</span> result[<span class="st">"policy"</span>]</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>Œµ_max_right <span class="op">=</span> result[<span class="st">"epsilon_max"</span>]</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>Œµ_min_right <span class="op">=</span> result[<span class="st">"epsilon_min"</span>]</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>env_right <span class="op">=</span> result[<span class="st">"env"</span>]</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>env_right.prob_steering_failure <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>loss_means_right <span class="op">=</span> result[<span class="st">"loss_means"</span>]</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>loss_means_starts_right <span class="op">=</span> result[<span class="st">"loss_means_starts"</span>]</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>loss_means_window_right <span class="op">=</span> result[<span class="st">"loss_means_window"</span>]</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The policy was trained for </span><span class="sc">{</span>n_episodes_right<span class="sc">:,}</span><span class="ss"> episodes."</span>)</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The Œµ decreased exponentially from </span><span class="sc">{Œµ</span>_max_right<span class="sc">}</span><span class="ss"> to </span><span class="sc">{Œµ</span>_min_right<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The policy was trained for 1,000,000,000 episodes.
The Œµ decreased exponentially from 0.25 to 0.025</code></pre>
</div>
</div>
<p>In many parts of the training the loss decreases like <span class="math inline">\(n^{-m}\)</span> for some <span class="math inline">\(m &lt; 1\)</span>. This is a typical behavior for Monte Carlo methods. I have highlighted one part where it scales approximately like <span class="math inline">\(n^{-1/4}\)</span>. I don‚Äôt know why the scaling is how it is.</p>
<div id="0fbdad6c" class="cell" data-execution_count="30">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Constants</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>START, END <span class="op">=</span> <span class="dv">750</span>, <span class="dv">1150</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Slice data</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> loss_means_starts_right[START:END]</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> loss_means_right[START:END]</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-transform for linear fitting</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>log_x, log_y <span class="op">=</span> np.log(x), np.log(y)</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear trend in log-log space</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>slope, intercept <span class="op">=</span> np.polyfit(log_x, log_y, <span class="dv">1</span>)</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>decay_rate <span class="op">=</span> np.exp(intercept) <span class="op">*</span> x<span class="op">**</span>slope</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>decay_rate_str <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>slope<span class="sc">:.2f}</span><span class="ss">"</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>plt.plot(loss_means_starts_right, loss_means_right, label<span class="op">=</span><span class="st">"Loss"</span>)</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>plt.plot(x, decay_rate, label<span class="op">=</span><span class="vs">rf"fit: </span><span class="dv">$</span><span class="vs">n</span><span class="dv">^</span><span class="ch">{{</span><span class="sc">{</span>decay_rate_str<span class="sc">}</span><span class="ch">}}</span><span class="dv">$</span><span class="vs">"</span>)</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Formatting</span></span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>plt.xscale(<span class="st">"log"</span>)</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>plt.yscale(<span class="st">"log"</span>)</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Loss averaged over </span><span class="sc">{</span>loss_means_window_right<span class="sc">:,}</span><span class="ss"> episodes"</span>)</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, which<span class="op">=</span><span class="st">"both"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-30-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12"><img src="05-monte-carlo-methods_files/figure-html/cell-30-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Now let‚Äôs see how the trajectories look like that this policy returns.</p>
<div id="fig-track-right" class="quarto-layout-panel">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-track-right-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-track-right" style="flex-basis: 33.3%;justify-content: flex-start;">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>states, _, _ <span class="op">=</span> generate_episode_soft(</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    env_right,</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    œÄ_right,</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.0</span>,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    rng,</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    max_lenght<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    start_pos<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>plot_episode(env_right, states)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-track-right-a" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-track-right-a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="6025e8d9" class="cell" data-execution_count="31">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-31-output-1.png" class="lightbox" data-gallery="fig-track-right" title="Figure&nbsp;5.7&nbsp;(a): The policy finds a good trajectory from all the left."><img src="05-monte-carlo-methods_files/figure-html/cell-31-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-track-right"></a></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-track-right-a-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(a) The policy finds a good trajectory from all the left.
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-track-right" style="flex-basis: 33.3%;justify-content: flex-start;">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>states, _, _ <span class="op">=</span> generate_episode_soft(</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    env_right,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    œÄ_right,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.0</span>,</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    rng,</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    max_lenght<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    start_pos<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">0</span>),</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>plot_episode(env_right, states)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-track-right-b" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-track-right-b-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="1871ceba" class="cell" data-execution_count="32">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-32-output-1.png" class="lightbox" data-gallery="fig-track-right" title="Figure&nbsp;5.7&nbsp;(b): The policy also finds a good trajector from the some starting positions on the right."><img src="05-monte-carlo-methods_files/figure-html/cell-32-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-track-right"></a></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-track-right-b-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(b) The policy also finds a good trajector from the some starting positions on the right.
</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell-subref quarto-layout-cell" data-ref-parent="fig-track-right" style="flex-basis: 33.3%;justify-content: flex-start;">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> random.Random(<span class="dv">8735</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>env_right.rng <span class="op">=</span> rng</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>states, _, _ <span class="op">=</span> generate_episode_soft(</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>    env_right,</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    œÄ_right,</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.0</span>,</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>    rng,</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    max_lenght<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>    start_pos<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>plot_episode(env_right, states)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-track-right-c" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-subfloat-fig figure">
<div aria-describedby="fig-track-right-c-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div id="b36d87e0" class="cell" data-execution_count="33">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="05-monte-carlo-methods_files/figure-html/cell-33-output-1.png" class="lightbox" data-gallery="fig-track-right" title="Figure&nbsp;5.7&nbsp;(c): For some other starting positions the policy just prefers to crash the car and gamble for anoter staring spot"><img src="05-monte-carlo-methods_files/figure-html/cell-33-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-track-right"></a></p>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-subfloat-caption quarto-subfloat-fig" id="fig-track-right-c-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
(c) For some other starting positions the policy just prefers to crash the car and gamble for anoter staring spot
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-track-right-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5.7: The policy has found pretty good strategies for some positions, as shown in (a) and (b). Other positions like the one shown in the last picture have a policy of crashing. , which rerols the starting position. In this example here, there are a couple of crashes until the car gets set to a position for which the policy knows how to finish the race.
</figcaption>
</figure>
</div>
</section>
</section>
</div>
</section>
<section id="appendix" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="appendix"><span class="header-section-number">5.8</span> üóê Appendix</h2>
<section id="sec-mc-is-slow" class="level3" data-number="5.8.1">
<h3 data-number="5.8.1" class="anchored" data-anchor-id="sec-mc-is-slow"><span class="header-section-number">5.8.1</span> Monte Carlo is Slow</h3>
<p>The biggest problem is that MC simulation improves very slowly on average. The rate of convergence can be estimate using the central limit theorem that says that the distribution of the sample mean <span class="math inline">\(\bar{X}_n\)</span> of <span class="math inline">\(n\)</span> samples <span class="math inline">\(X_1,\dots,X_n\)</span> approximates a normal distribution center around the true mean <span class="math inline">\(\mu\)</span>: <span class="math display">\[
\bar{X}_n \overset{d}{\to} \mathcal{N}(\mu, \frac{\sigma^2}{n}),
\]</span></p>
<p>where <span class="math inline">\(\sigma^2\)</span> is the true variance of the trials. We don‚Äôt know <span class="math inline">\(\mu\)</span> or <span class="math inline">\(\sigma\)</span> but we can use this to understand the rate of convergence of MC simulation.</p>
<p>As we are working with quite big <span class="math inline">\(n\)</span> in MC simulations we‚Äôll just do a leap of faith and work just say use <span class="math inline">\(\mathcal{N}(\mu, \frac{\sigma^2}{n})\)</span> for the distribution of <span class="math inline">\(\bar{X}_n\)</span> directly (in general this convergence is of the order <span class="math inline">\(\frac{1}{\sqrt{n}})\)</span>, see the <a href="https://en.wikipedia.org/wiki/Berry%E2%80%93Esseen_theorem">Berry‚ÄìEsseen theorem</a>, but we will ignore it here). Using the normal approximation this gives us that with a bit more than 95% probability <span class="math inline">\(\bar{X}_n\)</span> falls within the two sigma interval <span class="math inline">\([\mu - \frac{2\sigma}{\sqrt{n}}, \mu + \frac{2\sigma}{\sqrt{n}}]\)</span>. If we want to cut this interval in half, i.e., make <span class="math inline">\(\frac{2\sigma}{\sqrt{n}}\)</span> half as big, we have to quadruple the number of trials <span class="math inline">\(n\)</span>, and if we want to get another decimal point in precision we need 100 times more samples. That is really slow.</p>
<p>A saving grace for MC could be that it is very easy to scale in parallel computations but I don‚Äôt know how much that helps in real live and here in the real of these notes we are not dealing with any parallelisation.</p>
</section>
<section id="sec-confidence-intervals" class="level3" data-number="5.8.2">
<h3 data-number="5.8.2" class="anchored" data-anchor-id="sec-confidence-intervals"><span class="header-section-number">5.8.2</span> Confidence intervals</h3>
<p>We also should provide some error bars or something for the point estimate. The standard MC approach here is to basically use our estimates for the mean and standard deviations and drop them in <span class="math display">\[
\begin{split}
\hat{\mu} &amp;= \bar{X}_n = \frac{X_1 + \dots X_n}{n} \\
\hat{\sigma}^2 &amp;= \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X}_n)^2
\end{split}
\]</span></p>
<p>and say that <span class="math inline">\(\mu \in [\hat{\mu} - \frac{2\hat{\sigma}}{\sqrt{n}}, \mu + \frac{2\hat{\sigma}}{\sqrt{n}}]\)</span> with probability 95%. Well‚Ä¶ not quite we can only say that before we sampled our data that the true value will be in this interval with probability around 95%. Maybe there is a Bayesian reasoning that actually allows the former formulation, but let‚Äôs not get bogged down in to much scientific philosophy here and just follow good practise.</p>
</section>
<section id="sec-strip-problem" class="level3" data-number="5.8.3">
<h3 data-number="5.8.3" class="anchored" data-anchor-id="sec-strip-problem"><span class="header-section-number">5.8.3</span> The strip problem</h3>
<p>Consider the following discrete harmonic problem. The domain is a <span class="math inline">\(3\times(2r+1)\)</span> grid (<span class="math inline">\(3\)</span> rows and <span class="math inline">\(2r+1\)</span> columns). All boundary cells have value 0 except for the two boundary cells on the middle row‚Äîthe cells at <span class="math inline">\((1,0)\)</span> and <span class="math inline">\((1,2r)\)</span>‚Äîwhich have value 1.</p>
<p>Because the top and bottom rows are entirely boundary, the only non-trivial values lie along the middle row. Let <span class="math display">\[
f(i)=\text{value at } (1,i)\quad ,i=0,1,\dots,2r.
\]</span></p>
<p>By the boundary conditions and the four-neighbour averaging rule, the interior values satisfy <span id="eq-strip-problem"><span class="math display">\[
\begin{split}
f(0) &amp;= f(2r) = 1, \text{and} \\
f(i) &amp;= \frac{1}{4}(f(i-1) + f(i+1)) \text{ for } 0 &lt; i &lt; 2r.
\end{split}
\tag{5.7}\]</span></span></p>
<p>The theorem below gives the unique solution. In particular, the value at the centre, <span class="math inline">\(f(r)\)</span>, is given by <span class="math inline">\(1/g(r)\)</span>.</p>
<div id="thm-strip-problem" class="theorem">
<p><span class="theorem-title"><strong>Theorem 5.1</strong></span> The solution <span class="math inline">\(f(i)\)</span> for <a href="#eq-strip-problem" class="quarto-xref">Equation&nbsp;<span>5.7</span></a> is given by <span id="eq-strip-problem-solution"><span class="math display">\[
f(i) = \frac{g(|i-r|)}{g(r)}, \quad i = 0,1,\dots,2r
\tag{5.8}\]</span></span> where <span class="math inline">\(g \colon \mathbb{N} \to \mathbb{N}\)</span> is defined by <span class="math display">\[
g(n) = \begin{cases} 1 &amp;\text{if }n=0\\
2 &amp;\text{if }n=1\\
4g(n-1) - g(n-2) &amp;\text{if }n&gt;1
\end{cases}
\]</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Consider first the infinite version of the recurrence <span id="eq-strip-problem-infinite"><span class="math display">\[
f(i) = \frac{1}{4}(f(i-1)+ f(i+1)) \quad i \in \mathbb{Z}.
\tag{5.9}\]</span></span> Place a reference cell at <span class="math inline">\(i=0\)</span> with value <span class="math inline">\(1\)</span>, and look for a symmetric solution about this cell. Let <span class="math inline">\(g(n)\)</span> denote the value at distance <span class="math inline">\(n\)</span> from the centre. Then we have clearly <span class="math inline">\(g(0) = 1\)</span>. Also symmetry and <a href="#eq-strip-problem" class="quarto-xref">Equation&nbsp;<span>5.7</span></a> force the centre to be the average of its two neighbours, so <span class="math inline">\(g(1) = 2\)</span> because the center cell is the average of the two adjacent cells. Applying <a href="#eq-strip-problem-infinite" class="quarto-xref">Equation&nbsp;<span>5.9</span></a> at distance <span class="math inline">\(n&gt;1\)</span> yields the recurrenc <span class="math inline">\(g(n) = 4g(n-1) - g(n-2)\)</span>.</p>
<p>Since <a href="#eq-strip-problem-infinite" class="quarto-xref">Equation&nbsp;<span>5.9</span></a> is linear, any scalar multiple of <span class="math inline">\(g\)</span> is also a solution. For the finite strip, we rescale by <span class="math inline">\(g(r)\)</span> so that the values at distance <span class="math inline">\(r\)</span>‚Äîthe two boundary cells <span class="math inline">\((1,0)\)</span> and <span class="math inline">\((1,2r)\)</span>‚Äîare equal to 1. This gives the formula in <a href="#eq-strip-problem-solution" class="quarto-xref">Equation&nbsp;<span>5.8</span></a>.</p>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-agapiou2017Importance" class="csl-entry" role="listitem">
Agapiou, Sergios, Omiros Papaspiliopoulos, Daniel Sanz-Alonso, and Andrew M. Stuart. 2017. <span>‚ÄúImportance Sampling: Intrinsic Dimension and Computational Cost.‚Äù</span> <em>Statistical Science</em> 32 (3): 405‚Äì31. <a href="https://doi.org/10.1214/17-STS611">https://doi.org/10.1214/17-STS611</a>.
</div>
<div id="ref-eyal2006ActionElimination" class="csl-entry" role="listitem">
Even-Dar, Eyal, Shie Mannor, and Yishay Mansour. 2006. <span>‚ÄúAction Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems.‚Äù</span> <em>J. Mach. Learn. Res.</em> 7 (December): 1079‚Äì1105.
</div>
<div id="ref-oprea2000" class="csl-entry" role="listitem">
Oprea, John. 2000. <em>The Mathematics of Soap Films: Explorations with Maple: Explorations with Maple</em>. Fields Institute Communications. American Mathematical Society.
</div>
<div id="ref-sutton2018" class="csl-entry" role="listitem">
Sutton, Richard S., and Andrew G. Barto. 2018. <em>Reinforcement Learning: An Introduction</em>. Second edition. Adaptive Computation and Machine Learning Series. Cambridge, MA: MIT Press. <a href="https://mitpress.mit.edu/9780262039246/reinforcement-learning/">https://mitpress.mit.edu/9780262039246/reinforcement-learning/</a>.
</div>
</div>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>originally it says ‚Äòrear‚Äô but it my diagram it‚Äôs the top<a href="#fnref1" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p>originally it says whole last row on the left, since the ace was next to 2. I have arranged ace next to 10 though.<a href="#fnref2" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
<li id="fn3"><p>Maybe <code>negative_velocity_components</code> would have been a better name.<a href="#fnref3" class="footnote-back" role="doc-backlink">‚Ü©Ô∏é</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../chapters/04-dynamic-programming.html" class="pagination-link" aria-label="Dynamic Programming">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Dynamic Programming</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../chapters/06-temporal-difference-learning.html" class="pagination-link" aria-label="Temporal-Difference Learning (Still in Progress üî®)">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Temporal-Difference Learning (Still in Progress üî®)</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>